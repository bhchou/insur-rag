import os
import json
import time
from docx import Document
from pydantic import BaseModel, Field
from typing import List
from google import genai
from google.genai import types
from dotenv import load_dotenv

load_dotenv()

# --- è¨­å®š ---
if "GOOGLE_API_KEY" not in os.environ:
    print("âŒ éŒ¯èª¤: è«‹è¨­å®š GOOGLE_API_KEY")
    exit(1)

client = genai.Client(api_key=os.environ["GOOGLE_API_KEY"])

INPUT_DIR = "./data/raw_docx"        # DOCX ä¾†æº
OUTPUT_DIR = "./data/processed_json" # è¼¸å‡ºåˆ°è·Ÿ PDF JSON ä¸€æ¨£çš„åœ°æ–¹
os.makedirs(OUTPUT_DIR, exist_ok=True)

# --- å®šç¾©è³‡æ–™çµæ§‹ (åŒ…å«åŒç¾©è© Mapping) ---

class SynonymEntry(BaseModel):
    slang: str = Field(description="å®¢æˆ¶å¸¸èªªçš„å£èª (å¦‚: æ­»æ‰, æ®˜å»¢, å­˜éŒ¢)")
    formal: str = Field(description="å°æ‡‰çš„ä¿å–®å°ˆæ¥­è¡“èª (å¦‚: èº«æ•…çµ¦ä»˜, å®Œå…¨å¤±èƒ½)")

class FaqItem(BaseModel):
    q: str = Field(description="ä½¿ç”¨è€…å¯èƒ½å•çš„å•é¡Œ")
    a: str = Field(description="ç°¡çŸ­å›ç­”")

class BasicInfo(BaseModel):
    product_name: str = Field(description="å®Œæ•´å•†å“åç¨±")
    product_code: str = Field(description="å‚™æŸ¥æ–‡è™Ÿ/æ ¸å‡†æ–‡è™Ÿ (ä¾‹å¦‚: 114.01.01è‡ºå£½å­—ç¬¬...è™Ÿ)")
    company: str = Field(description="ä¿éšªå…¬å¸åç¨±")
    currency: List[str] = Field(description="å¹£åˆ¥åˆ—è¡¨ (ä¾‹å¦‚: ['TWD', 'USD'])")
    product_type: str = Field(description="å•†å“é¡å‹æè¿° (ä¾‹å¦‚: è®Šé¡è¬èƒ½å£½éšª, å‚³çµ±å‹ç¾å…ƒé¤Šè€éšª)")
    payment_period: str = Field(description="ç¹³è²»å¹´æœŸ/æ–¹å¼")

class Conditions(BaseModel):
    age_range: str = Field(description="æŠ•ä¿å¹´é½¡é™åˆ¶")
    premium_limit: str = Field(description="ä¿è²»é–€æª»é™åˆ¶")
    fees_and_discounts: str = Field(description="ç›¸é—œè²»ç”¨ç‡æˆ–é«˜ä¿è²»æŠ˜æ‰£èªªæ˜")

class Coverage(BaseModel):
    death_benefit: str = Field(description="èº«æ•…/å–ªè‘¬çµ¦ä»˜è¨ˆç®—é‚è¼¯")
    maturity_benefit: str = Field(description="æ»¿æœŸ/ç¥å£½é‡‘çµ¦ä»˜é‚è¼¯")
    other_benefits: List[str] = Field(description="å…¶ä»–çµ¦ä»˜é …ç›® (å¦‚å®Œå…¨å¤±èƒ½, æ„å¤–çµ¦ä»˜)")

class Investment(BaseModel):
    is_investment_linked: bool = Field(description="æ˜¯å¦ç‚ºæŠ•è³‡å‹ä¿å–®")
    features: List[str] = Field(description="æŠ•è³‡ç‰¹è‰² (å¦‚: ['æœˆæ’¥å›', 'å…¨æ¬Šå§”è¨—'])")
    risks: List[str] = Field(description="é¢¨éšªæ­éœ²")

class RagData(BaseModel):
    keywords: List[str] = Field(description="æª¢ç´¢é—œéµå­—åˆ—è¡¨")
    # ğŸ”¥ é€™æ˜¯ DOCX ç‰ˆç‰¹æœ‰çš„å¼·é …ï¼šåŒç¾©è©å°ç…§è¡¨
    synonym_mapping: List[SynonymEntry] = Field(description="å£èªèˆ‡å°ˆæ¥­è¡“èªå°ç…§è¡¨")
    target_audience: str = Field(description="é©åˆå®¢ç¾¤")
    faq: List[FaqItem] = Field(description="å¸¸è¦‹å•ç­”")

class PolicyData(BaseModel):
    basic_info: BasicInfo
    conditions: Conditions
    coverage: Coverage
    investment: Investment
    rag_data: RagData

# --- æ ¸å¿ƒå‡½å¼ ---

def extract_text_from_docx(file_path):
    try:
        doc = Document(file_path)
        full_text = []
        for para in doc.paragraphs:
            if para.text.strip():
                full_text.append(para.text)
        return "\n".join(full_text)
    except Exception as e:
        print(f"âŒ è®€å– DOCX å¤±æ•—: {e}")
        return None

def process_single_docx(file_path, filename):
    print(f"   ğŸ“„ è®€å– DOCX: {filename}...")
    text_content = extract_text_from_docx(file_path)
    
    if not text_content: return None

    try:
        print("   ğŸ¤– Gemini åˆ†æä¸­...")
        response = client.models.generate_content(
            model="gemini-3-flash-preview", 
            contents=[
                f"ä½ æ˜¯ä¸€ä½ä¿éšªå°ˆå®¶ã€‚è«‹åˆ†æé€™ä»½æ–‡ä»¶ (æª”å: {filename}) ä¸¦æå– RAG æ‰€éœ€è³‡æ–™ï¼Œç‰¹åˆ¥æ˜¯ã€å®¢æˆ¶å£èª vs å°ˆæ¥­è¡“èªã€çš„å°ç…§ã€‚",
                text_content[:30000] 
            ],
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=PolicyData,
                temperature=0.1
            )
        )

        if response.parsed:
            data = response.parsed.model_dump()
            data["source_filename"] = filename
            return data
        return None

    except Exception as e:
        print(f"âŒ Gemini è™•ç†å¤±æ•—: {e}")
        return None

# --- ä¸»ç¨‹å¼ ---
if __name__ == "__main__":
    if not os.path.exists(INPUT_DIR):
        print(f"âš ï¸ ç›®éŒ„ä¸å­˜åœ¨: {INPUT_DIR} (è«‹å»ºç«‹ä¸¦æ”¾å…¥ .docx æª”)")
        exit(0)

    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(".docx")]
    print(f"ğŸš€ é–‹å§‹è™•ç† {len(files)} å€‹ DOCX æª”æ¡ˆ")
    
    for filename in files:
        json_name = os.path.splitext(filename)[0] + ".json"
        save_path = os.path.join(OUTPUT_DIR, json_name)
        
        if os.path.exists(save_path):
            print(f"â© è·³éå·²å­˜åœ¨: {filename}")
            continue

        print(f"\nğŸ”„ è™•ç†: {filename}")
        result = process_single_docx(os.path.join(INPUT_DIR, filename), filename)
        
        if result:
            with open(save_path, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"âœ… å®Œæˆ")
        
        time.sleep(1)