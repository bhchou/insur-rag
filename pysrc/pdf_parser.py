import pdfplumber
import json
import sys
import pytesseract
import requests
import re
from PIL import Image
import os
from dotenv import load_dotenv

load_dotenv()

# ==========================================
# ğŸ”§ è¨­å®šå€ (è«‹ä¾æ“šæ‚¨çš„å¯¦éš›ç’°å¢ƒä¿®æ”¹)
# ==========================================
#
VLLM_ENDPOINT = os.getenv("VLLM_ENDPOINT")  # ä¾‹å¦‚: http://192.168.1.100:8000
MODEL_NAME = os.getenv("MODEL_NAME")              # ä¾‹å¦‚: meta-llama/Llama-3-8b-instruct
BEARER_TOKEN = os.getenv("BEARER_TOKEN")

def clean_json_string(text):
    """
    æ¸…ç† LLM å›å‚³çš„å­—ä¸²ï¼Œç§»é™¤ Markdown æ¨™è¨˜
    """
    cleaned = re.sub(r"```json\s*", "", text)
    cleaned = re.sub(r"```\s*", "", cleaned)
    return cleaned.strip()

def extract_metadata_via_llm(text_content):
    """
    å‘¼å« VLLM API é€²è¡Œ Metadata æå–
    """
    # 1. URL æ™ºæ…§è™•ç† (è‡ªå‹•è£œå…¨ /v1)
    base_url = VLLM_ENDPOINT.rstrip('/')
    if '/v1' in base_url:
        api_url = f"{base_url}/chat/completions"
    else:
        api_url = f"{base_url}/v1/chat/completions"

    # 2. Header è¨­å®š (é¿å… 401 éŒ¯èª¤)
    headers = {
        "Content-Type": "application/json",
        "User-Agent": "PDF-Parser"
    }
    # åªæœ‰ç•¶ Token æœ‰æ•ˆä¸”ä¸æ˜¯ none æ™‚æ‰åŠ å…¥ Authorization
    if BEARER_TOKEN and str(BEARER_TOKEN).lower() not in ['none', '', 'null']:
        headers["Authorization"] = f"Bearer {BEARER_TOKEN}"

        
    #url = f"{VLLM_ENDPOINT}/v1/chat/completions"
    
    # è¨­ç½®è«‹æ±‚æ¨™é ­ (åƒè€ƒæ‚¨æä¾›çš„ç¨‹å¼ç¢¼)
    #headers = {"Content-Type": "application/json"}
    #if BEARER_TOKEN:
    #    headers["Authorization"] = f"Bearer {BEARER_TOKEN}"

    ###
    # å®šç¾©æç¤ºè© (System Prompt + User Context)
    system_instruction = """
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä¿éšªæ–‡ä»¶åˆ†æå¸«ã€‚è«‹åˆ†æä½¿ç”¨è€…æä¾›çš„ OCR æ–‡å­—ï¼Œæå–ä»¥ä¸‹ JSON æ¬„ä½ã€‚
    å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰è³‡è¨Šï¼Œè«‹å¡« null æˆ–ç©ºé™£åˆ— []ã€‚
    
    å¿…é ˆæå–çš„æ¬„ä½:
    1. product_name (å­—ä¸²): ç”¢å“å…¨å
    2. product_code (å­—ä¸²): æ–‡è™Ÿæˆ–å•†å“ä»£ç¢¼
    3. insurance_type (å­—ä¸²é™£åˆ—): ä¾‹å¦‚ ["çµ‚èº«å£½éšª", "ç¾å…ƒä¿å–®", "åˆ©ç‡è®Šå‹•å‹"]
    4. target_audience (å­—ä¸²): é©åˆçš„å°è±¡æè¿°
    5. benefits (å­—ä¸²é™£åˆ—): ä¸»è¦çµ¦ä»˜é …ç›®
    6. currency (å­—ä¸²): å¹£åˆ¥ (å¦‚ USD, TWD)

    è«‹ç›´æ¥å›å‚³ JSON ç‰©ä»¶ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡‹æˆ– Markdown æ ¼å¼ã€‚
    """

    # ç‚ºäº†é¿å…è¶…é Token ä¸Šé™ï¼Œæˆ‘å€‘åªå–å‰ 3000 å€‹å­— (é€šå¸¸ metadata éƒ½åœ¨å‰å¹¾é )
    truncated_text = text_content[:3000]
    final_prompt = f"{system_instruction}\n\n=== å¾…åˆ†ææ–‡æœ¬ ===\n{truncated_text}"

    # 4. å»ºæ§‹ Payload
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "user", "content": final_prompt}
        ],
        "temperature": 0.1, # ä½æº«ä»¥ç¢ºä¿è¼¸å‡ºæ ¼å¼ç©©å®š
        #"max_tokens": 1024,
        "stream": False
    }

    try:
        print(f"[Python] Calling LLM: {api_url}...", file=sys.stderr)
        response = requests.post(api_url, headers=headers, json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            #content = resp_json["choices"][0]["message"]["content"]
            
            # æ¸…ç†ä¸¦è§£æ JSON
            #cleaned_content = clean_json_string(content)
            #print(f"[Python] LLM Response: {cleaned_content}...", file=sys.stderr) # debug log
            
            #return json.loads(cleaned_content)
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content']
                return clean_json_string(content)
            else:
                print(f"[Error] Empty choices in response", file=sys.stderr)
                return "{}"
        else:
            print(f"[Error] VLLM API Error: {response.status_code} - {response.text}", file=sys.stderr)
            return {}

    except Exception as e:
        print(f"[Error] Connection failed: {str(e)}", file=sys.stderr)
        return {}

def parse_pdf(file_path):
    """
    (é€™æ˜¯FOR PYO)
    è®€å– PDFï¼Œç°¡å–®éæ¿¾é é¦–é å°¾ï¼Œå›å‚³çµæ§‹åŒ–è³‡æ–™ã€‚
    """
    result = {
        "file_path": file_path,
        "pages": [],
        "debug_info": [],
        "metadata": {}
    }

    full_text = ""
    
    try:
        with pdfplumber.open(file_path) as pdf:
            if len(pdf.pages) == 0:
                return json.dumps({"error": "PDF has 0 pages."})

            for i, page in enumerate(pdf.pages):
                # å…ˆæå–æ–‡å­—çœ‹çœ‹
                
                text = page.extract_text()
                method = "text_layer"

                # å¦‚æœæ–‡å­—å¤ªå°‘ (ä¾‹å¦‚ DM è½‰å¤–æ¡†)ï¼Œå‰‡å•Ÿå‹• OCR
                if not text or len(text.strip()) < 10:
                    try:
                        # å°‡é é¢è½‰ç‚ºåœ–ç‰‡ (è§£æåº¦ 300 dpi ä»¥æå‡è¾¨è­˜ç‡)
                        im = page.to_image(resolution=300).original
                        # ä½¿ç”¨ Tesseract è¾¨è­˜ç¹é«”ä¸­æ–‡ (chi_tra) + è‹±æ–‡ (eng)
                        text = pytesseract.image_to_string(im, lang='chi_tra+eng')
                        method = "ocr_fallback"
                    except Exception as e:
                        result["debug_info"].append(f"Page {i+1} OCR failed: {str(e)}")
                
                if text and len(text.strip()) > 0:
                    #ç°¡å–®æ¸…æ´—
                    clean_text = text.strip()

                    result["pages"].append({
                        "page_number": i + 1,
                        "content": clean_text,
                        "method": method # æ¨™è¨˜æ˜¯ç”¨ä»€éº¼æ–¹æ³•è®€åˆ°çš„
                    })
                    full_text += clean_text + "\n"

                else:
                    # è®€ä¸åˆ°æ–‡å­—ï¼Œè¨˜éŒ„åŸå› 
                    result["debug_info"].append(f"Page {i+1}: No text layer found. (Likely scanned image or encrypted)")
        
        # --- å‘¼å« LLM é€²è¡Œ Metadata æå– ---
        if len(full_text) > 0:
            # ç¢ºä¿æœ‰è¨­å®š Endpoint æ‰å‘¼å«
            if "YOUR_VLLM_IP" not in VLLM_ENDPOINT: 
                result["metadata"] = extract_metadata_via_llm(full_text)
            else:
                result["debug_info"].append("Skipped LLM call: VLLM_ENDPOINT not configured.")
                
    except Exception as e:
        return json.dumps({"error": str(e)})

    return json.dumps(result, ensure_ascii=False)

def extract_text_from_pdf(file_path):
    """
    è®€å– PDF ä¸¦è½‰ç‚ºç´”æ–‡å­— (å« OCR Fallback)
    """
    full_text = ""
    print(f"[Python] Processing PDF: {file_path}", file=sys.stderr)
    
    try:
        with pdfplumber.open(file_path) as pdf:
            if len(pdf.pages) == 0:
                return ""

            for i, page in enumerate(pdf.pages):
                # å˜—è©¦ç›´æ¥æå–æ–‡å­—
                text = page.extract_text()
                
                # å¦‚æœæ–‡å­—å¤ªå°‘ï¼Œå•Ÿå‹• OCR
                if not text or len(text.strip()) < 10:
                    try:
                        print(f"[Python] Page {i+1} using OCR...", file=sys.stderr)
                        # è§£æåº¦ 300 dpi ä»¥æå‡è¾¨è­˜ç‡
                        im = page.to_image(resolution=300).original
                        text = pytesseract.image_to_string(im, lang='chi_tra+eng')
                    except Exception as e:
                        print(f"[Python] Page {i+1} OCR failed: {e}", file=sys.stderr)
                
                if text:
                    full_text += text.strip() + "\n"
                    
    except Exception as e:
        print(f"[Error] PDF Read Failed: {e}", file=sys.stderr)
        return ""
        
    return full_text

def main():
    # æª¢æŸ¥åƒæ•¸
    if len(sys.argv) < 2:
        # éŒ¯èª¤è¨Šæ¯ä¹Ÿè¼¸å‡ºæˆ JSON æ ¼å¼ï¼Œæ–¹ä¾¿ Rust åˆ¤è®€
        print(json.dumps({"error": "No file path provided"}))
        return

    pdf_path = sys.argv[1]
    
    # 1. æå–å…¨æ–‡ (Full Text)
    raw_text = extract_text_from_pdf(pdf_path)
    
    if not raw_text:
        # å¦‚æœè®€ä¸åˆ°å­—ï¼Œå›å‚³ç©ºçš„çµæ§‹é¿å… Rust è§£æå¤±æ•—
        final_output = {
            "metadata": {
                "product_name": "Unknown",
                "product_code": None,
                "insurance_type": [],
                "benefits": [],
                "currency": "Unknown",
                "target_audience": None
            },
            "full_text": ""
        }
        print(json.dumps(final_output, ensure_ascii=False))
        return

    # 2. å‘¼å« LLM æå– Metadata
    metadata_json_str = extract_metadata_via_llm(raw_text)
    
    # å˜—è©¦è§£æ LLM å›å‚³çš„ JSON
    try:
        metadata_obj = json.loads(metadata_json_str)
    except:
        print(f"[Python] JSON Parse Failed, Raw: {metadata_json_str}", file=sys.stderr)
        # Fallback çµæ§‹
        metadata_obj = {
            "product_name": "Unknown", 
            "product_code": None,
            "insurance_type": [],
            "benefits": [],
            "currency": "Unknown",
            "target_audience": None
        }

    # 3. çµ„è£æœ€çµ‚çµæ§‹
    final_output = {
        "metadata": metadata_obj,
        "full_text": raw_text
    }

    # 4. è¼¸å‡ºåˆ° Stdout (Rust è®€å–ç›®æ¨™)
    print(json.dumps(final_output, ensure_ascii=False))

if __name__ == "__main__":
    main()

