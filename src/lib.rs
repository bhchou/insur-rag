pub mod models;

use futures::TryStreamExt;
use dotenvy::dotenv; 
use serde_json::{Value, json};
use walkdir::WalkDir;
use serde::{Serialize, Deserialize};
use regex::Regex;

use std::collections::{HashMap, HashSet};
use std::env; 

use std::sync::Arc;
use std::error::Error;
use std::fs;
use tokio::sync::Mutex;

// LanceDB èˆ‡ Arrow ç›¸é—œå¼•å…¥
use lancedb::{connect, query::{ExecutableQuery, QueryBase}};
use arrow_schema::{Schema, Field, DataType};
use arrow_array::{RecordBatch, RecordBatchIterator, StringArray, Array};
use fastembed::{TextEmbedding, InitOptions, EmbeddingModel};

// --- è¨­å®šå€ ---
const PROCESSED_JSON_DIR: &str = "./data/processed_json";
const DB_URI: &str = "data/lancedb_insure";
const TABLE_NAME: &str = "insurance_docs";

#[derive(Clone)]
pub struct ProductSummary {
    pub name: String,
    pub intro: String, // é€™è£¡æœƒå­˜ï¼šå•†å“é¡å‹ + ç‰¹è‰² + é©åˆå°è±¡
}

// --- Rerank API çµæ§‹ ---
#[derive(Serialize)]
struct RerankRequest {
    query: String,
    documents: Vec<String>,
}

#[derive(Deserialize)]
struct RerankResponse {
    scores: Vec<f32>,
    indices: Vec<usize>,
}

pub struct AppState {
    pub db: lancedb::Connection,
    pub model: Mutex<TextEmbedding>, // æ³¨æ„ï¼šModel ä¸æ˜¯ç·šç¨‹å®‰å…¨çš„ï¼Œè¦åŠ  Mutex
    pub synonyms: HashMap<String, String>,
    pub summaries: HashMap<String, ProductSummary>,
    pub llm_provider: String,
    pub google_api_key: String,
    pub local_llm_url: String,
    pub local_llm_model: String,
}

#[derive(Serialize, Debug)]
pub struct RagResponse {
    pub answer: String,
    pub sources: Vec<String>,
}

fn load_system_prompt() -> String {
    // 1. å˜—è©¦å¾ env è®€å–è·¯å¾‘
    let path = env::var("SYSTEM_PROMPT_PATH").unwrap_or("./data/system_prompt.txt".to_string());
    
    // 2. è®€å–æª”æ¡ˆå…§å®¹
    match fs::read_to_string(path.clone()) {
        Ok(content) => {
            println!("ğŸ“œ å·²è¼‰å…¥ System Prompt ({} bytes)", content.len());
            content
        },
        Err(e) => {
            println!("âš ï¸ ç„¡æ³•è®€å– Prompt æª”æ¡ˆ ({})ï¼Œä½¿ç”¨å…§å»ºé è¨­å€¼ã€‚éŒ¯èª¤: {}", path, e);
            // é€™è£¡æ”¾ä¸€å€‹æœ€ç°¡å–®çš„é è¨­å€¼ç•¶ä½œå‚™æ¡ˆ
            "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä¿éšªé¡§å•ã€‚è«‹æ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”å•é¡Œã€‚".to_string()
        }
    }
}

// --- 5. ç”Ÿæˆå›ç­” (Generation) ---
async fn ask_llm(state: &Arc<AppState>, context: &str, query: &str) -> Result<String, Box<dyn Error>> {
    match state.llm_provider.as_str() {
        "local" => ask_local_llm(state, context, query).await,
        "google" => ask_google_gemini(state, context, query).await,
        _ => {
            println!("âš ï¸ æœªçŸ¥ Provider: {}ï¼Œé è¨­ä½¿ç”¨ Google", state.llm_provider);
            ask_google_gemini(state, context, query).await
        }
    }
}

async fn ask_local_llm(state: &Arc<AppState>, context: &str, query: &str) -> Result<String, Box<dyn Error>> {
    let system_prompt_text = load_system_prompt();
    println!("ğŸ¤– æ­£åœ¨è©¢å• LLM (é€™å¯èƒ½éœ€è¦å¹¾ç§’é˜)...");


    let user_prompt = format!(
        "åƒè€ƒè³‡æ–™ï¼š\n{}\n\nä½¿ç”¨è€…å•é¡Œï¼š{}", 
        context, query
    );

    // 2. æº–å‚™ HTTP Client (ä¿ç•™æ‚¨çš„ no_proxy è¨­å®š)
    let client = reqwest::Client::builder()
        .no_proxy() // ä¸è¦ç®¡ http_proxy/HTTP_PROXY
        .build()?; 
    
    let token = env::var("BEARER_TOKEN").unwrap_or_default();
    
    let base_url = state.local_llm_url.trim_end_matches('/');     
    let api_url = if base_url.contains("/v1") {
        format!("{}/chat/completions", base_url)
    } 
    else {
        format!("{}/v1/chat/completions", base_url)
    };

    println!("ğŸ”— é€£ç·š Endpoint: {}", api_url);
    
    // ç™¼é€è«‹æ±‚ (OpenAI Compatible API æ ¼å¼)
    let body = json!({
        "model": state.local_llm_model, 
        "messages": [
            { "role": "system", "content": system_prompt_text },
            { "role": "user", "content": user_prompt }
        ],
        "temperature": 0.1, 
        "stream": false     
    });

    let mut request_builder = client.post(&api_url)
        .header("Content-Type", "application/json")
        .header("User-Agent", "INSUR-RAG");

    // Token æª¢æŸ¥é‚è¼¯
    let token_check = token.trim().to_lowercase();
    let invalid_values = ["", "none", "null"];
    if !invalid_values.contains(&token_check.as_str()) {
        request_builder = request_builder.header("Authorization", format!("Bearer {}", token));
    }

    let res = request_builder
        .json(&body)
        .send() 
        .await?;

    // è§£æå›æ‡‰
    if res.status().is_success() {
        let response_json: Value = res.json().await?;
        
        // æŠ“å– choices[0].message.content
        if let Some(content) = response_json["choices"][0]["message"]["content"].as_str() {
            // println!("\nğŸ’¬ LLM å›ç­”ï¼š\n==================================\n{}\n==================================", content);
            return Ok(content.to_string())
        } 
        else {
            return Err(format!("LLM å›æ‡‰æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•æ‰¾åˆ°å›ç­”å…§å®¹: {:?}", response_json).into());
        }
    } 
    else {
        return Err(format!("âŒ LLM è«‹æ±‚å¤±æ•—: Status {}\nResponse: {}", res.status(), res.text().await?).into());

    }

}

// --- LLM APIï¼šæœ€çµ‚å›ç­” (RAG Generation) é€™éƒ¨åˆ†é€€ä¼‘å¾Œç”¨ ---
async fn ask_google_gemini(state: &Arc<AppState>, context: &str, query: &str) -> Result<String, Box<dyn Error>> {
    // æª¢æŸ¥æœ‰æ²’æœ‰ Key
    if state.google_api_key.is_empty() {
        return Err("ç¼ºå°‘ GOOGLE_API_KEY".into());
    }    
    let system_prompt_text = load_system_prompt();
    let client = reqwest::Client::new();
    let full_prompt = format!("{}\n\nåƒè€ƒè³‡æ–™:\n{}\n\nä½¿ç”¨è€…å•é¡Œ: {}", system_prompt_text, context, query);

    let request_body = json!({
        "contents": [{ "parts": [{ "text": full_prompt }] }]
    });

    let url = format!("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={}",
                    state.google_api_key);

    match client.post(&url).json(&request_body).send().await {
        Ok(resp) => {
            if let Ok(json) = resp.json::<serde_json::Value>().await {
                if let Some(text) = json["candidates"][0]["content"]["parts"][0]["text"].as_str() {
                    return Ok(text.to_string());
                } 
                else {
                    return Err("âŒ LLM å›å‚³æ ¼å¼éŒ¯èª¤æˆ–ç„¡å…§å®¹".into());
                }
            } else {
                return Err("âŒ ç„¡æ³•è§£æ LLM å›æ‡‰".into());
            }
        }
        Err(e) => return Err(format!("âŒ API å‘¼å«å¤±æ•—: {}", e).into())
    }
}

/* for JSON and then */

// --- 3. å•ç­”é‚è¼¯ ---
pub async fn process_query(
    state: &Arc<AppState>,
    history: &[Value],
    user_query: &str,
) -> Result<RagResponse, Box<dyn Error>> {
    
    let mut model = state.model.lock().await; 
    let db = &state.db;
    let synonyms = &state.synonyms;
    let summaries = &state.summaries;

    // --- è®€å–ç’°å¢ƒè®Šæ•¸ (è¨­å®šé è¨­å€¼ä»¥é˜²æ²’è¨­) ---
    let recall_limit = env::var("RAG_RECALL_LIMIT").ok().and_then(|v| v.parse().ok()).unwrap_or(20);
    let rerank_limit = env::var("RAG_RERANK_LIMIT").ok().and_then(|v| v.parse().ok()).unwrap_or(3);
    let rerank_api = env::var("RERANK_API_URL").unwrap_or("http://localhost:8000/rerank".to_string());
    // -------------------------------------
    // åœ¨ process_query ä¸€é–‹å§‹
    let mut normalized_query = user_query.to_string();

    // 1. å¼·åˆ¶å°‡æ•¸å­—èˆ‡ä¸­æ–‡ä¹‹é–“æ’å…¥ç©ºç™½
    // æŠŠ "30æ­²" è®Šæˆ "30 æ­²"ï¼ŒæŠŠ "100è¬" è®Šæˆ "100 è¬"
    let re_num_zh = Regex::new(r"(\d+)([\u4e00-\u9fa5])").unwrap();
    normalized_query = re_num_zh.replace_all(&normalized_query, "$1 $2").to_string();

    let re_zh_num = Regex::new(r"([\u4e00-\u9fa5])(\d+)").unwrap();
    normalized_query = re_zh_num.replace_all(&normalized_query, "$1 $2").to_string();

    println!("ğŸ”§ æ­£è¦åŒ–æŸ¥è©¢: '{}' -> '{}'", user_query, normalized_query);
    let mut search_target = normalized_query.clone();

    // 0. å­—å…¸æ“´å……
    // let mut final_query = user_query.to_string();
    for (slang, term) in synonyms {
        if user_query.contains(slang) {
            println!("ğŸ’¡ [å­—å…¸å‘½ä¸­] '{}' -> åŠ ä¸Š '{}'", slang, term);
            search_target.push_str(" ");
            search_target.push_str(term);
        }
    }

    // [ç­–ç•¥ B] ä¸»å‹•å¼ AI æ„åœ–æ”¹å¯« (Pre-emptive Rewrite) ğŸ”¥ é€™æ˜¯å‰›æ‰è¨è«–çš„é‡é»
    // æ¢ä»¶ï¼šæœ‰æ­·å²ç´€éŒ„ AND (å•é¡Œå¾ˆçŸ­ OR åŒ…å«ä»£åè©)
    // é€™è£¡æˆ‘å€‘ç°¡å–®ç”¨å­—æ•¸åˆ¤æ–· (< 20 å­—)
    let should_rewrite = !history.is_empty() && user_query.chars().count() < 20;
    
    if should_rewrite {
        println!("ğŸ¤” åµæ¸¬åˆ°çŸ­å•é¡Œä¸”æœ‰æ­·å²ï¼Œå˜—è©¦é€²è¡Œã€Œä¸»å‹•æ„åœ–æ”¹å¯«ã€...");
        if let Some(rewritten) = expand_query_with_ai(state, history, user_query).await {
            println!("âœ… AI æ”¹å¯«æˆåŠŸ: '{}'", rewritten);
            // å¦‚æœæ”¹å¯«æˆåŠŸï¼Œæˆ‘å€‘ç›´æ¥ç”¨æ”¹å¯«å¾Œçš„å¥å­ä½œç‚ºä¸»è¦æœå°‹ç›®æ¨™
            // (é€šå¸¸ AI æ”¹å¯«å¾Œå·²ç¶“åŒ…å«å…·é«”åè©ï¼Œä¸éœ€è¦å†ç–ŠåŠ åŒç¾©è©ï¼Œæˆ–è€…è¦–æƒ…æ³ç–ŠåŠ )
            search_target = rewritten; 
        }
    } 
    else {
        println!("â„¹ï¸ ç„¡éœ€ AI æ”¹å¯« (ç„¡æ­·å²æˆ–å•é¡Œå¤ å®Œæ•´)ï¼Œä½¿ç”¨åŸå§‹æŸ¥è©¢");
    }

    let mut forced_candidates: Vec<(String, String, f32)> = Vec::new();
    let mut forced_filenames = HashSet::new();

    // 1. æå–æ‹¬å¼§å…§çš„æ–‡å­— (æ”¯æ´ ã€ã€ ã€Œã€ æˆ– "")
    // é€™é‚Šå‡è¨­ä½¿ç”¨è€…æœƒç”¨é€™äº›å¸¸è¦‹æ‹¬å¼§
    let re = Regex::new(r#"[ã€ã€Œã€Šã€â€œ"â€˜'ï¼ˆ\(](.*?)[ã€ã€ã€‹ã€‘â€"â€™'ï¼‰\)]"#).unwrap();
    
    for cap in re.captures_iter(user_query) {
        let keyword = &cap[1]; // æå–åˆ°çš„é—œéµå­—ï¼Œä¾‹å¦‚ "æ´»åˆ©å„ªé€€"
        println!("ğŸ¯ åµæ¸¬åˆ°æ˜ç¢ºæ„åœ–é—œéµå­—: {}", keyword);

        // 2. æƒæ Summary æ‰¾å°æ‡‰æª”æ¡ˆ
        for (filename, summary) in &state.summaries {
            // è¦å‰‡ï¼šåªè¦æª”åæˆ–å•†å“å…¨ååŒ…å«é€™å€‹é—œéµå­— -> å‘½ä¸­
            if filename.contains(keyword) || summary.name.contains(keyword) {
                println!("âœ… é–å®šæª”æ¡ˆ: {}", filename);
                forced_filenames.insert(filename.clone());
            }
        }
    }
    // 3. å¦‚æœæœ‰é–å®šçš„æª”æ¡ˆï¼Œç›´æ¥å» DB æ’ˆå‡ºä¾† (ä¸é€éå‘é‡æœå°‹)
    if !forced_filenames.is_empty() {
        // çµ„è£ SQL Filter: source_file = 'A' OR source_file = 'B'
        let filter_cond = forced_filenames
            .iter()
            .map(|f| format!("source_file = '{}'", f))
            .collect::<Vec<_>>()
            .join(" OR ");

        let table = state.db.open_table(TABLE_NAME).execute().await?;
        let specific_results = table
            .query()
            .only_if(filter_cond)
            .limit(10) // æ¯å€‹æª”æ¡ˆæŠ“å‰å¹¾æ®µæ‘˜è¦å³å¯
            .execute()
            .await?;

        let batches: Vec<RecordBatch> = specific_results.try_collect().await?;
        
        // å°‡çµæœè½‰ç‚º candidates æ ¼å¼
        for batch in batches {
            let src_col = batch.column_by_name("source_file").unwrap().as_any().downcast_ref::<StringArray>().unwrap();
            let txt_col = batch.column_by_name("text").unwrap().as_any().downcast_ref::<StringArray>().unwrap();
            
            for i in 0..batch.num_rows() {
                let src = src_col.value(i).to_string();
                let txt = txt_col.value(i).to_string();
                // ğŸ”¥ çµ¦äºˆç„¡é™å¤§çš„åˆ†æ•¸ (f32::INFINITY)ï¼Œç¢ºä¿å®ƒåœ¨ Re-rank å‰çµ•å°æ˜¯ç¬¬ä¸€å
                forced_candidates.push((src, txt, f32::INFINITY));
            }
        }
    }

    // 1. å‘é‡åŒ–å•é¡Œ
    // let query_embedding = model.embed(vec![user_query.to_string()], None)?;
    // let query_vector = query_embedding[0].clone();
    // let query_vec = model.embed(vec![final_query.clone()], None)?[0].clone();
    println!("ğŸ” åŸ·è¡Œå‘é‡æœå°‹: {}", search_target);
    let query_vec = model.embed(vec![search_target.clone()], None)?[0].clone();
    // 2. æœå°‹ DB
    let table = db.open_table(TABLE_NAME).execute().await?;
    let results = table
        .query()
        .nearest_to(query_vec)?
        .limit(recall_limit) // å–å‰ 3 å€‹æœ€ç›¸é—œçš„ç‰‡æ®µ
        .execute()
        .await?;


    let vector_batches: Vec<RecordBatch> = results.try_collect().await?;

    // --- 5. å€™é¸çµæœåˆä½µ (Merge & Deduplicate) ---
    let mut raw_candidates: Vec<(String, String)> = Vec::new();
    let mut seen_texts = HashSet::new();

    // (1) å„ªå…ˆæ”¾å…¥å¼·åˆ¶å‘½ä¸­çš„
    for (src, txt, _) in forced_candidates {
        if seen_texts.insert(txt.clone()) {
            raw_candidates.push((src, txt));
        }
    }

    // (2) å†æ”¾å…¥å‘é‡æœå°‹çš„
    for b in vector_batches {
        let src_col = b.column_by_name("source_file").unwrap().as_any().downcast_ref::<StringArray>().unwrap();
        let txt_col = b.column_by_name("text").unwrap().as_any().downcast_ref::<StringArray>().unwrap();

        for i in 0..b.num_rows() {
            let txt = txt_col.value(i).to_string();
            if seen_texts.insert(txt.clone()) {
                raw_candidates.push((
                    src_col.value(i).to_string(),
                    txt
                ));
            }
        }
    }

    
    // --- 6. æª¢æŸ¥çµæœ (Fallback é‚è¼¯å¯é¸) ---
    // ç”±æ–¼æˆ‘å€‘å‰é¢å·²ç¶“åšäº† Pre-emptive Rewriteï¼Œé€™è£¡çš„ Fallback é‡è¦æ€§é™ä½
    // ä½†å¦‚æœä½ æƒ³ä¿ç•™ã€Œæœä¸åˆ°æ±è¥¿æ™‚å†è©¦ä¸€æ¬¡ã€çš„é‚è¼¯ï¼Œå¯ä»¥å¯«åœ¨é€™è£¡
    // ä¸éæ ¹æ“šæ–°ç­–ç•¥ï¼Œé€šå¸¸ä¸éœ€è¦äºŒæ¬¡ Embedding äº†

    if raw_candidates.is_empty() {
        return Ok(RagResponse {
            answer: "æŠ±æ­‰ï¼Œè³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚".to_string(),
            sources: vec![],
        });
    }
    // ğŸ”¥ [éå°ç¨±éæ¿¾ç­–ç•¥]
    // å®šç¾©éœ€è¦ã€Œåš´æ ¼éæ¿¾ã€çš„éšªç¨®ã€‚å£½éšªã€æ„å¤–éšªå› ç‚ºå¤ªå»£æ³›ï¼Œæ•…æ„ä¸åˆ—å…¥ï¼Œä¿æŒå¯¬é¬†ã€‚
    let strict_rules = vec![
        ("é†«ç™‚", vec!["é†«ç™‚", "æ‰‹è¡“", "ä½é™¢", "å¯¦æ”¯å¯¦ä»˜", "å¥åº·ä¿éšª"]),
        ("ç™Œç—‡", vec!["ç™Œç—‡", "é˜²ç™Œ", "æƒ¡æ€§è…«ç˜¤", "åŒ–ç™‚", "æ¨™é¶"]),
        ("é•·ç…§", vec!["é•·ç…§", "é•·æœŸç…§é¡§", "å¤±èƒ½", "æ‰¶åŠ©"]),
        ("æ‰“å·¥", vec!["æ‰“å·¥", "éŠå­¸", "åº¦å‡", "æµ·å¤–"]),
        ("æŠ•è³‡", vec!["æŠ•è³‡", "åŸºé‡‘", "è®Šé¡", "æ”¶ç›Š"]),
    ];
    // 2. å®šç¾©ã€Œå—ä¿è­·ã€çš„å¯¬é¬†éšªç¨® (ç•¶åš´æ ¼æ¨¡å¼å•Ÿå‹•æ™‚ï¼Œé€™äº›é—œéµå­—ä¹Ÿè¦è¢«å…è¨±)
    let protected_rules = vec![
        ("å£½éšª", vec!["å£½éšª", "èº«æ•…", "äººå£½", "å„²è“„", "é‚„æœ¬"]),
        ("æ„å¤–", vec!["æ„å¤–", "å‚·å®³", "éª¨æŠ˜", "ç”¢éšª"]),
    ];

    let mut allowed_keywords: Vec<&str> = Vec::new();
    let mut strict_mode_triggered = false;

    // 3. æƒæåš´æ ¼è¦å‰‡ (æ”¯æ´å¤šé‡å‘½ä¸­)
    for (category, keywords) in &strict_rules {
        if user_query.contains(category) {
            println!("ğŸ¯ åµæ¸¬åˆ°åš´æ ¼é¡åˆ¥æ„åœ–: [{}]", category);
            allowed_keywords.extend(keywords.iter().cloned());
            strict_mode_triggered = true;
        }
    }

    if strict_mode_triggered {
        for (category, keywords) in &protected_rules {
            if user_query.contains(category) {
                println!("ğŸ›¡ï¸ åµæ¸¬åˆ°æ··åˆæ„åœ–ï¼ŒåŠ å…¥å—ä¿è­·é¡åˆ¥: [{}]", category);
                allowed_keywords.extend(keywords.iter().cloned());
            }
        }
    }

    // 5. åŸ·è¡Œéæ¿¾ (åªæœ‰åœ¨åš´æ ¼æ¨¡å¼è§¸ç™¼æ™‚æ‰åš)
    if !allowed_keywords.is_empty() {
        let before_count = raw_candidates.len();
        
        raw_candidates.retain(|(src, txt)| {
            // è¦å‰‡ï¼š(A OR B OR C...) åªè¦å‘½ä¸­å…¶ä¸­ä¸€çµ„é—œéµå­—å³å¯ä¿ç•™
            let src_match = allowed_keywords.iter().any(|&k| src.contains(k));
            let txt_match = allowed_keywords.iter().any(|&k| txt.chars().take(200).collect::<String>().contains(k));
            
            src_match || txt_match
        });

        println!("ğŸ§¹ æ··åˆéæ¿¾åŸ·è¡Œ: {} -> {} ç­† (é—œéµå­—è¯é›†: {:?})", 
            before_count, raw_candidates.len(), allowed_keywords);

        // é˜²å‘†ï¼šå¦‚æœæ¿¾å®Œè®Š 0 ç­† (ä¾‹å¦‚ User åŒæ™‚å•äº†å…©å€‹è³‡æ–™åº«éƒ½æ²’æœ‰çš„éšªç¨®)
        if raw_candidates.is_empty() {
             println!("âš ï¸ éæ¿¾å¾Œç„¡çµæœï¼Œå–æ¶ˆéæ¿¾æ¢ä»¶ã€‚");
             // é€™è£¡å»ºè­°å›å¾©å‚™ä»½ï¼Œæˆ–è€…å°±è®“å®ƒå›å‚³ç„¡çµæœ
        }
    }



    // --- 7. Re-ranking (é—œéµå„ªåŒ–) ---
    // æ³¨æ„ï¼šRerank æ™‚å»ºè­°ç”¨ã€Œæ”¹å¯«å¾Œçš„ search_targetã€é‚„æ˜¯ã€ŒåŸå§‹ user_queryã€ï¼Ÿ
    // å»ºè­°ï¼šç”¨ search_target (å› ç‚ºå®ƒæ¶ˆé™¤äº†ä»£åè©)ï¼ŒReranker æ¯”è¼ƒçœ‹å¾—æ‡‚
    let top_results_all = rerank_documents(&search_target, raw_candidates, summaries, recall_limit, &rerank_api).await?;
    let top_results: Vec<(String, String, f32)> = top_results_all.into_iter().take(rerank_limit).collect();

    if top_results.is_empty() {
         return Ok(RagResponse {
            answer: "é›–ç„¶æœ‰ç›¸é—œæ–‡æª”ï¼Œä½†ç¶“éç›¸é—œæ€§æª¢æ¸¬å¾Œè¢«éæ¿¾æ‰äº†ã€‚".to_string(),
            sources: vec![],
        });
    }

    // 5. çµ„è£ Context (åŒ…å«å•†å“æ‘˜è¦)
    let mut hit_files = HashSet::new();
    let mut snippets_text = String::new();

    println!("\nğŸ” [RAG æª¢ç´¢çµæœ]");
   
    for (src, txt, score) in &top_results {
        hit_files.insert(src.clone());
        // æˆ‘å€‘å¯ä»¥åœ¨ context è£¡ç¨å¾®æ¨™è¨»ä¸€ä¸‹é€™æ˜¯ç²¾é¸å‡ºä¾†çš„
        snippets_text.push_str(&format!("ğŸ“„ [ç²¾é¸ç‰‡æ®µ] (é—œè¯åº¦:{:.1}) ä¾†æº: {}\nå…§å®¹: {}\n\n", score, src, txt));
    }

    // 6. æ³¨å…¥æ‘˜è¦ (Summary Injection)
    let mut final_context = String::new();
    final_context.push_str("=== ç›¸é—œå•†å“åŸºæœ¬ä»‹ç´¹ ===\n");
    for filename in &hit_files {
        if let Some(summary) = summaries.get(filename) {
            final_context.push_str(&format!("ğŸ“„ ä¾†æº: {}\n{}\n", filename, summary.intro));
        }
    }
    final_context.push_str("========================\n\n");
    final_context.push_str("=== è©³ç´°æª¢ç´¢ç‰‡æ®µ ===\n");
    final_context.push_str(&snippets_text);

    // 7. æœ€å¾Œç”Ÿæˆ
    //ask_llm(&final_context, user_query).await?;
    let llm_answer = ask_llm(state, &final_context, &search_target).await?;
    
    // æ•´ç†ä¾†æºåˆ—è¡¨
    let mut sorted_sources: Vec<String> = hit_files.into_iter().collect();
    sorted_sources.sort();

    // âœ… å›å‚³çµæ§‹åŒ–è³‡æ–™
    Ok(RagResponse {
        answer: llm_answer,
        sources: sorted_sources,
    })
}

// å›å‚³ (æ‘˜è¦Map, åŒç¾©è©Map)
fn load_data_from_json_dir() -> (HashMap<String, ProductSummary>, HashMap<String, String>) {
    let mut summaries = HashMap::new();
    let mut synonyms = HashMap::new();
    
    println!("ğŸš€ Rust æ­£åœ¨æƒæ JSON è³‡æ–™å¤¾å»ºç«‹å¿«å–...");
    
    let walker = WalkDir::new(PROCESSED_JSON_DIR).into_iter();
    
    for entry in walker.filter_map(|e| e.ok()) {
        let path = entry.path();
        if path.extension().map_or(false, |e| e == "json") {
            if let Ok(content) = fs::read_to_string(path) {
                // å˜—è©¦è§£æ JSON
                if let Ok(data) = serde_json::from_str::<models::PolicyData>(&content) {
                    
                    // --- 1. è™•ç†æ‘˜è¦ (åŸæœ‰é‚è¼¯) ---
                    let intro = format!(
                        "ã€å•†å“ç¸½è¦½ã€‘\nåç¨±: {}\né¡å‹: {}\nç‰¹è‰²: {:?}\né©åˆå°è±¡: {}\n",
                        data.basic_info.product_name,
                        data.basic_info.product_type,
                        data.investment.features,
                        data.rag_data.target_audience
                    );

                    summaries.insert(data.source_filename.clone(), ProductSummary {
                        name: data.basic_info.product_name,
                        intro,
                    });

                    // --- 2. è™•ç†åŒç¾©è© (æ–°å¢é‚è¼¯) ---
                    // å‡è¨­ models::RagData è£¡é¢æœ‰ synonym_mapping æ¬„ä½
                    // æ³¨æ„ï¼šæ‚¨éœ€è¦åœ¨ models.rs è£¡å°æ‡‰åŠ ä¸Šé€™å€‹æ¬„ä½ï¼Œå¦‚æœæ²’æœ‰çš„è©±
                    if let Some(mapping) = &data.rag_data.synonym_mapping {
                        for entry in mapping {
                            // è™•ç†é€—è™Ÿåˆ†éš” (ä¾‹å¦‚: "æ­»æ‰, èµ°äº†")
                            let slangs: Vec<&str> = entry.slang.split(&['ã€', ','][..]).collect();
                            for s in slangs {
                                let clean_s = s.trim().to_string();
                                if !clean_s.is_empty() {
                                    // å»ºç«‹åå‘ç´¢å¼•: å£èª -> å°ˆæ¥­è¡“èª
                                    synonyms.insert(clean_s, entry.formal.clone());
                                }
                            }
                        }
                    }
                }
            }
        }
    }
    
    println!("ğŸ“š è³‡æ–™è¼‰å…¥å®Œæˆï¼");
    println!("   - å•†å“æ‘˜è¦: {} ç­†", summaries.len());
    println!("   - åŒç¾©è©åº«: {} ç­†", synonyms.len());
    
    (summaries, synonyms)
}

pub async fn expand_query_with_ai(state: &Arc<AppState>, history: &[Value], query: &str) -> Option<String> {
    // å»ºç«‹æŒ‡ä»£æ¶ˆè§£å°ˆç”¨çš„ System Prompt
    let system_prompt = r#"
    ä½ æ˜¯ä¸€å€‹æœå°‹æ„åœ–å„ªåŒ–å°ˆå®¶ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šã€Œå°è©±æ­·å²ã€ä¾†æ”¹å¯«ä½¿ç”¨è€…çš„ã€Œæœ€æ–°å•é¡Œã€ï¼Œä½¿å…¶æˆç‚ºç¨ç«‹å®Œæ•´çš„æœå°‹èªå¥ã€‚
    
    ã€æ ¸å¿ƒè¦å‰‡ã€‘ï¼š
    1. **ç¹¼æ‰¿ã€Œäººã€çš„ç‰¹å¾µ**ï¼šæ°¸é ä¿ç•™æ­·å²ä¸­çš„ã€Œä½¿ç”¨è€…ç•«åƒã€ï¼ˆå¦‚ï¼šå¹´é½¡ã€æ€§åˆ¥ã€è·æ¥­ã€å®¶åº­ç‹€æ³ï¼‰ã€‚
    2. **åˆ¤æ–·ã€Œç‰©ã€çš„å»ç•™**ï¼š
       - **æƒ…å¢ƒ A (è¿½å•ç´°ç¯€)**ï¼šå¦‚æœä½¿ç”¨è€…å•çš„æ˜¯ã€Œè²»ç”¨ã€ã€ã€Œç†è³ ã€ã€ã€Œæ¢æ¬¾ã€ï¼Œå‰‡**ä¿ç•™**ä¸Šä¸€å€‹è¨è«–çš„å•†å“åç¨±ã€‚
         (ä¾‹ï¼šã€Œé‚£å®ƒè²´å—ï¼Ÿã€ -> ã€Œ[ä¸Šä¸€å€‹å•†å“] çš„ä¿è²»è²»ç”¨ã€)
       - **æƒ…å¢ƒ B (åˆ‡æ›è©±é¡Œ)**ï¼šå¦‚æœä½¿ç”¨è€…å•çš„æ˜¯ã€Œå¦ä¸€å€‹éšªç¨®ã€ï¼ˆå¦‚ï¼šå£½éšªã€ç™Œç—‡éšªã€æ„å¤–éšªï¼‰ï¼Œå‰‡**æ¨æ£„**ä¸Šä¸€å€‹å•†å“ï¼Œåªä¿ç•™ä½¿ç”¨è€…ç•«åƒã€‚
         (ä¾‹ï¼šã€Œé‚£å£½éšªå‘¢ï¼Ÿã€ -> ã€Œ[30æ­²ç”·æ€§] é©åˆçš„å£½éšªæ¨è–¦ã€)
    
    3. **è¼¸å‡ºè¦æ±‚**ï¼š
       - ç›´æ¥è¼¸å‡ºæ”¹å¯«å¾Œçš„å¥å­ã€‚
       - ä¸è¦è§£é‡‹ï¼Œä¸è¦åŠ å¼•è™Ÿã€‚
    "#;
    
    // æº–å‚™æ­·å²è¨Šæ¯å­—ä¸² (çµ¦ Gemini æˆ– Local LLM åƒè€ƒç”¨)
    // æˆ‘å€‘å–æœ€å¾Œ 4 å¥å°±å¥½ï¼Œé¿å… Token çˆ†ç‚¸
    let history_text = history.iter()
        .rev() // å¾æ–°åˆ°èˆŠ
        .take(4)
        .rev() // è½‰å›ä¾†
        .map(|v| format!("{}: {}", v["role"].as_str().unwrap_or("unknown"), v["content"].as_str().unwrap_or("")))
        .collect::<Vec<String>>()
        .join("\n");

    let full_context = format!("å°è©±æ­·å²:\n{}\n\nä½¿ç”¨è€…æœ€æ–°å•é¡Œ: {}", history_text, query);

    println!("ğŸ¤– [AI æ”¹å¯«] æ­£åœ¨åˆ†ææ„åœ–...");

    let result = match state.llm_provider.as_str() {
        "local" => expand_local(state, system_prompt, &full_context).await,
        "google" => expand_google(state, system_prompt, &full_context).await,
        _ => expand_google(state, system_prompt, &full_context).await, // é è¨­ Google
    };

    match result {
        Ok(rewritten) => {
            let clean = rewritten.trim().replace("\n", " ");
            println!("âœ¨ åŸå§‹å•é¡Œ: {}", query);
            println!("âœ¨ æ”¹å¯«å¾Œå•é¡Œ: {}", clean);
            Some(clean)
        },
        Err(e) => {
            eprintln!("âŒ æ„åœ–æ”¹å¯«å¤±æ•—ï¼Œå°‡ä½¿ç”¨åŸå§‹å•é¡Œ: {}", e);
            None // å¤±æ•—å›å‚³ Noneï¼Œå¤–å±¤é‚è¼¯æœƒè‡ªå‹•é€€å›ä½¿ç”¨åŸå§‹ query
        }
    }
}

// è·¯å¾‘ 1: æœ¬åœ° LLM (ä½¿ç”¨ .no_proxy())
async fn expand_local(state: &Arc<AppState>, system_prompt: &str, user_content: &str) -> Result<String, Box<dyn Error>> {
    // ğŸ”¥ é—œéµï¼šé€™è£¡å¿…é ˆç”¨ no_proxyï¼Œå¦å‰‡é€£ä¸åˆ° host.docker.internal
    let client = reqwest::Client::builder()
        .no_proxy()
        .build()?;

    let base_url = state.local_llm_url.trim_end_matches('/');
    let api_url = if base_url.contains("/v1") {
        format!("{}/chat/completions", base_url)
    } else {
        format!("{}/v1/chat/completions", base_url)
    };

    let token = std::env::var("BEARER_TOKEN").unwrap_or_default();

    let body = json!({
        "model": state.local_llm_model,
        "messages": [
            { "role": "system", "content": system_prompt },
            { "role": "user", "content": user_content } // é€™è£¡æŠŠæ­·å²+å•é¡ŒåŒ…åœ¨ä¸€èµ·çµ¦å®ƒ
        ],
        "temperature": 0.1, // æ”¹å¯«ä¸éœ€è¦å‰µæ„ï¼Œè¶Šä½è¶Šå¥½
        "max_tokens": 100   // æ”¹å¯«é€šå¸¸å¾ˆçŸ­
    });

    let mut request_builder = client.post(&api_url)
        .header("Content-Type", "application/json");

    if !token.is_empty() && token != "none" {
        request_builder = request_builder.header("Authorization", format!("Bearer {}", token));
    }

    let resp = request_builder.json(&body).send().await?;
    let resp_status = resp.status();

    if resp.status().is_success() {
        let json: Value = resp.json().await?;
        if let Some(content) = json["choices"][0]["message"]["content"].as_str() {
            return Ok(content.to_string());
        }
    }
    
    Err(format!("Local LLM å›æ‡‰éŒ¯èª¤: {}", resp_status).into())
}

// è·¯å¾‘ 2: Google Gemini (ä½¿ç”¨æ¨™æº– Proxy)
async fn expand_google(state: &Arc<AppState>, system_prompt: &str, user_content: &str) -> Result<String, Box<dyn Error>> {
    if state.google_api_key.is_empty() {
        return Err("ç¼ºå°‘ GOOGLE_API_KEY".into());
    }

    // ğŸ”¥ é—œéµï¼šé€™è£¡ä½¿ç”¨é è¨­ Clientï¼Œæœƒè‡ªå‹•è®€å– HTTPS_PROXY ç’°å¢ƒè®Šæ•¸
    let client = reqwest::Client::new();

    // Gemini çš„ Prompt çµ„åˆæ–¹å¼
    let full_prompt = format!("{}\n\n{}", system_prompt, user_content);

    let url = format!(
        "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={}",
        state.google_api_key
    );

    let body = json!({
        "contents": [{ "parts": [{ "text": full_prompt }] }],
        "generationConfig": {
            "temperature": 0.1,
            "maxOutputTokens": 100
        }
    });

    let resp = client.post(&url).json(&body).send().await?;

    let resp_status = resp.status();

    if resp.status().is_success() {
        let json: Value = resp.json().await?;
        if let Some(text) = json["candidates"][0]["content"]["parts"][0]["text"].as_str() {
            return Ok(text.to_string());
        }
    }

    Err(format!("Google API å›æ‡‰éŒ¯èª¤: {}", resp_status).into())
}


// âœ… ä¿®æ”¹å‡½å¼ç°½åï¼šè¼¸å…¥æ”¹ç‚º candidates: Vec<(String, String)>
async fn rerank_documents(
    query: &str,
    candidates: Vec<(String, String)>, // (source_file, text)
    summaries: &HashMap<String, ProductSummary>,
    top_k: usize,
    api_url: &str
) -> Result<Vec<(String, String, f32)>, Box<dyn Error>> {

    let max_chunks_per_doc = env::var("MAX_CHUNKS_PER_DOC")
        .unwrap_or("3".to_string())
        .parse::<usize>()
        .unwrap_or(3);
    
    if candidates.is_empty() {
        return Ok(Vec::new());
    }

    // 1. æº–å‚™çµ¦ Re-ranker API çš„è³‡æ–™
    // æˆ‘å€‘éœ€è¦ä¿ç•™åŸå§‹çš„ (src, txt) å°æ‡‰é—œä¿‚ï¼ŒåŒæ™‚æº–å‚™ä¸€ä»½ã€Œæ³¨å…¥æ‘˜è¦ã€çš„ç‰ˆæœ¬çµ¦ AI è®€
    let mut doc_texts_for_api: Vec<String> = Vec::new();

    for (src, txt) in &candidates {
        // ç‚ºäº†è®“ Re-ranker åˆ¤æ–·æº–ç¢ºï¼Œæˆ‘å€‘æŠŠã€Œæ‘˜è¦ã€ä¹ŸåŠ é€²å»çµ¦å®ƒè®€
        // é€™æ¨£å®ƒæ‰çŸ¥é“ "å„ªåˆ©ç²¾é¸" æ˜¯æŠ•è³‡å‹ä¿å–®
        let content_for_judge = if let Some(sum) = summaries.get(src) {
            format!("{}\næ–‡ä»¶å…§å®¹: {}", sum.intro, txt)
        } else {
            txt.clone()
        };
        doc_texts_for_api.push(content_for_judge);
    }

    // 2. å‘¼å« Python Re-ranker API
    // let client = reqwest::Client::new();
    let client = reqwest::Client::builder()
        .no_proxy()
        .build()?;
    let request_body = RerankRequest {
        query: query.to_string(),
        documents: doc_texts_for_api,
    };

    println!("âš–ï¸ æ­£åœ¨é€²è¡Œ Re-ranking ({} ç­†å€™é¸, å– Top {} åˆ° {})...", candidates.len(), top_k, api_url);

    let resp = client.post(api_url)
        .json(&request_body)
        .send()
        .await?;

    let rerank_res: RerankResponse = resp.json().await?;

    // 3. æ ¹æ“šå›å‚³çš„ indices é‡æ–°çµ„è£çµæœ
    let mut ranked_results = Vec::new();
    let mut file_counts: HashMap<String, usize> = HashMap::new();
    
    for (i, &original_idx) in rerank_res.indices.iter().enumerate() {
        if ranked_results.len() >= top_k { break; }
        
        let score = rerank_res.scores[i];
        
        // ğŸ’¡ é–€æª»å€¼éæ¿¾
        if score < -5.0 { 
            continue; 
        }

        // ğŸ”¥ é—œéµæ”¹è®Šï¼šç›´æ¥å¾å‚³å…¥çš„ candidates å–å€¼
        // original_idx æ˜¯ Python å›å‚³çš„åŸå§‹ç´¢å¼•ï¼Œå°æ‡‰åˆ° candidates çš„é †åº
        let (src, txt) = &candidates[original_idx];
        
        // æª¢æŸ¥é€™ä»½æª”æ¡ˆæ˜¯å¦å·²ç¶“é¡æ»¿ (å¤šæ¨£æ€§éæ¿¾)
        let count = file_counts.entry(src.clone()).or_insert(0);
        
        if *count < max_chunks_per_doc {
            println!("   â­ [Top {}] åˆ†æ•¸: {:.2} | ä¾†æº: {}", i+1, score, src);
            ranked_results.push((src.clone(), txt.clone(), score));
            *count += 1;
        }
        else {
            println!("   â­ï¸ [è·³é] æª”æ¡ˆé¡æ»¿ ({}/{}): {:.2} | ä¾†æº: {}", *count, max_chunks_per_doc, score, src);
        }
    }

    Ok(ranked_results)
}


// 4. æ–°å¢åˆå§‹åŒ–å‡½å¼ (å¾åŸæœ¬ main æå–)
pub async fn init_system() -> Result<Arc<AppState>, Box<dyn Error>> {
    dotenv().ok();
    
    let db_path = std::env::var("LANCEDB_PATH").unwrap_or(DB_URI.to_string());
    println!("ğŸ“‚ é€£æ¥ LanceDB è·¯å¾‘: {}", db_path);
    let db = connect(&db_path).execute().await?;
    // åˆå§‹åŒ– DB
    //let db = connect(DB_URI).execute().await?;
    //println!("ğŸ’¾ é€£ç·šè‡³è³‡æ–™åº«: {}", DB_URI);

    //å»ºç«‹ Table (å¦‚æœä¸å­˜åœ¨)
    // æ³¨æ„: é€™è£¡å®šç¾© Schema
    let embedding_dim = 768;
    let schema = Arc::new(Schema::new(vec![
        Field::new("source_file", DataType::Utf8, false),
        Field::new("file_hash", DataType::Utf8, false), // â˜… æ–°å¢é€™ä¸€æ¬„
        Field::new("text", DataType::Utf8, false),
        Field::new("vector", DataType::FixedSizeList(
            Arc::new(Field::new("item", DataType::Float32, true)),
            embedding_dim
        ), false),
    ]));

    let table_names = db.table_names().execute().await?;
    let _table = if table_names.contains(&TABLE_NAME.to_string()) {
        println!("ğŸ“‚ è³‡æ–™è¡¨ '{}' å·²å­˜åœ¨ï¼Œé–‹å•Ÿä¸­...", TABLE_NAME);
        db.open_table(TABLE_NAME).execute().await?
    } 
    else {
        println!("âœ¨ è³‡æ–™è¡¨ '{}' ä¸å­˜åœ¨ï¼Œå»ºç«‹ä¸­...", TABLE_NAME);
        // å»ºç«‹ä¸€å€‹ç©ºçš„è¿­ä»£å™¨ä¾†åˆå§‹åŒ–è¡¨çµæ§‹
        let batches: Vec<Result<RecordBatch, arrow_schema::ArrowError>> = vec![]; 
        db.create_table(TABLE_NAME, RecordBatchIterator::new(batches, schema.clone()))
            .execute()
            .await?
    };
    
    println!("ğŸ§  è¼‰å…¥ Embedding æ¨¡å‹...");
    let model = TextEmbedding::try_new(InitOptions::new(EmbeddingModel::BGEBaseENV15))?;
    
    // è¼‰å…¥è³‡æ–™ (é€™è£¡å‡è¨­æ‚¨å·²ç¶“åˆä½µäº†è®€å–å‡½å¼ï¼Œæˆ–ä¿ç•™åŸæœ¬åˆ†é–‹çš„)
    //let summaries = load_product_summaries(); 
    //let synonyms = load_synonyms();
    let (summaries, synonyms) = load_data_from_json_dir();
    let llm_provider = env::var("LLM_PROVIDER").unwrap_or("google".to_string());
    let google_api_key = env::var("GOOGLE_API_KEY").unwrap_or_default();
    let local_llm_url = env::var("VLLM_ENDPOINT").unwrap_or("http://localhost:8000/v1/chat/completions".to_string());
    let local_llm_model = env::var("MODEL_NAME").unwrap_or("local-model".to_string());

    Ok(Arc::new(AppState {
        db,
        model: Mutex::new(model),
        synonyms,
        summaries,
        llm_provider,
        google_api_key,
        local_llm_url,
        local_llm_model,
    }))
}
