pub mod models;

use futures::TryStreamExt;
use dotenvy::dotenv; 
use serde_json::{Value, json};
use walkdir::WalkDir;
use serde::{Serialize, Deserialize};
use regex::Regex;

use std::collections::{HashMap, HashSet};
use std::env; 
use std::sync::Arc;
use std::error::Error;
use std::fs;
use tokio::sync::Mutex;
use std::path::PathBuf;

use sha2::{Sha256, Digest};

// use redis::Client;
use deadpool_redis::{Config, Runtime, Pool};

// LanceDB èˆ‡ Arrow ç›¸é—œå¼•å…¥
use lancedb::{connect, query::{ExecutableQuery, QueryBase, Select}};
use arrow_schema::{Schema, Field, DataType};
use arrow_array::{RecordBatch, RecordBatchIterator, StringArray, Array, Float32Array, FixedSizeListArray};
use fastembed::{TextEmbedding, InitOptions, EmbeddingModel};

// --- è¨­å®šå€ ---
const PROCESSED_JSON_DIR: &str = "./data/processed_json";
const DB_URI: &str = "data/lancedb_insure";
const TABLE_NAME: &str = "insurance_docs";

#[derive(Clone)]
pub struct ProductSummary {
    pub name: String,
    pub intro: String, // é€™è£¡æœƒå­˜ï¼šå•†å“é¡å‹ + ç‰¹è‰² + é©åˆå°è±¡
}

// --- Rerank API çµæ§‹ ---
#[derive(Serialize)]
struct RerankRequest {
    query: String,
    documents: Vec<String>,
}

#[derive(Deserialize)]
struct RerankResponse {
    scores: Vec<f32>,
    indices: Vec<usize>,
}

pub struct AppState {
    pub db: lancedb::Connection,
    pub model: Mutex<TextEmbedding>, // æ³¨æ„ï¼šModel ä¸æ˜¯ç·šç¨‹å®‰å…¨çš„ï¼Œè¦åŠ  Mutex
    pub synonyms: HashMap<String, String>,
    pub summaries: HashMap<String, ProductSummary>,
    pub llm_provider: String,
    pub google_api_key: String,
    pub local_llm_url: String,
    pub local_llm_model: String,
   // pub redis_client: Option<Client>,
    pub redis_pool: Option<Pool>,
}

#[derive(Serialize, Debug)]
pub struct RagResponse {
    pub answer: String,
    pub sources: Vec<String>,
}

fn calculate_hash(content: &str) -> String {
    let mut hasher = Sha256::new();
    hasher.update(content);
    hex::encode(hasher.finalize())
}

fn load_system_prompt() -> String {
    // 1. å˜—è©¦å¾ env è®€å–è·¯å¾‘
    let path = env::var("SYSTEM_PROMPT_PATH").unwrap_or("./data/system_prompt.txt".to_string());
    
    // 2. è®€å–æª”æ¡ˆå…§å®¹
    match fs::read_to_string(path.clone()) {
        Ok(content) => {
            println!("ğŸ“œ å·²è¼‰å…¥ System Prompt ({} bytes)", content.len());
            content
        },
        Err(e) => {
            println!("âš ï¸ ç„¡æ³•è®€å– Prompt æª”æ¡ˆ ({})ï¼Œä½¿ç”¨å…§å»ºé è¨­å€¼ã€‚éŒ¯èª¤: {}", path, e);
            // é€™è£¡æ”¾ä¸€å€‹æœ€ç°¡å–®çš„é è¨­å€¼ç•¶ä½œå‚™æ¡ˆ
            "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä¿éšªé¡§å•ã€‚è«‹æ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”å•é¡Œã€‚".to_string()
        }
    }
}

// --- 5. ç”Ÿæˆå›ç­” (Generation) ---
async fn ask_llm(state: &Arc<AppState>, context: &str, query: &str) -> Result<String, Box<dyn Error>> {
    match state.llm_provider.as_str() {
        "local" => ask_local_llm(state, context, query).await,
        "google" => ask_google_gemini(state, context, query).await,
        _ => {
            println!("âš ï¸ æœªçŸ¥ Provider: {}ï¼Œé è¨­ä½¿ç”¨ Google", state.llm_provider);
            ask_google_gemini(state, context, query).await
        }
    }
}

async fn ask_local_llm(state: &Arc<AppState>, context: &str, query: &str) -> Result<String, Box<dyn Error>> {
    let system_prompt_text = load_system_prompt();
    println!("ğŸ¤– æ­£åœ¨è©¢å• LLM (é€™å¯èƒ½éœ€è¦å¹¾ç§’é˜)...");


    let user_prompt = format!(
        "åƒè€ƒè³‡æ–™ï¼š\n{}\n\nä½¿ç”¨è€…å•é¡Œï¼š{}", 
        context, query
    );

    // 2. æº–å‚™ HTTP Client (ä¿ç•™æ‚¨çš„ no_proxy è¨­å®š)
    let client = reqwest::Client::builder()
        .no_proxy() // ä¸è¦ç®¡ http_proxy/HTTP_PROXY
        .build()?; 
    
    let token = env::var("BEARER_TOKEN").unwrap_or_default();
    
    let base_url = state.local_llm_url.trim_end_matches('/');     
    let api_url = if base_url.contains("/v1") {
        format!("{}/chat/completions", base_url)
    } 
    else {
        format!("{}/v1/chat/completions", base_url)
    };

    println!("ğŸ”— é€£ç·š Endpoint: {}", api_url);
    
    // ç™¼é€è«‹æ±‚ (OpenAI Compatible API æ ¼å¼)
    let body = json!({
        "model": state.local_llm_model, 
        "messages": [
            { "role": "system", "content": system_prompt_text },
            { "role": "user", "content": user_prompt }
        ],
        "temperature": 0.1, 
        "stream": false     
    });

    let mut request_builder = client.post(&api_url)
        .header("Content-Type", "application/json")
        .header("User-Agent", "INSUR-RAG");

    // Token æª¢æŸ¥é‚è¼¯
    let token_check = token.trim().to_lowercase();
    let invalid_values = ["", "none", "null"];
    if !invalid_values.contains(&token_check.as_str()) {
        request_builder = request_builder.header("Authorization", format!("Bearer {}", token));
    }

    let res = request_builder
        .json(&body)
        .send() 
        .await?;

    // è§£æå›æ‡‰
    if res.status().is_success() {
        let response_json: Value = res.json().await?;
        
        // æŠ“å– choices[0].message.content
        if let Some(content) = response_json["choices"][0]["message"]["content"].as_str() {
            // println!("\nğŸ’¬ LLM å›ç­”ï¼š\n==================================\n{}\n==================================", content);
            return Ok(content.to_string())
        } 
        else {
            return Err(format!("LLM å›æ‡‰æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•æ‰¾åˆ°å›ç­”å…§å®¹: {:?}", response_json).into());
        }
    } 
    else {
        return Err(format!("âŒ LLM è«‹æ±‚å¤±æ•—: Status {}\nResponse: {}", res.status(), res.text().await?).into());

    }

}

// --- LLM APIï¼šæœ€çµ‚å›ç­” (RAG Generation) é€™éƒ¨åˆ†é€€ä¼‘å¾Œç”¨ ---
async fn ask_google_gemini(state: &Arc<AppState>, context: &str, query: &str) -> Result<String, Box<dyn Error>> {
    // æª¢æŸ¥æœ‰æ²’æœ‰ Key
    if state.google_api_key.is_empty() {
        return Err("ç¼ºå°‘ GOOGLE_API_KEY".into());
    }    
    let system_prompt_text = load_system_prompt();
    let client = reqwest::Client::new();
    let full_prompt = format!("{}\n\nåƒè€ƒè³‡æ–™:\n{}\n\nä½¿ç”¨è€…å•é¡Œ: {}", system_prompt_text, context, query);

    let request_body = json!({
        "contents": [{ "parts": [{ "text": full_prompt }] }]
    });

    let url = format!("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={}",
                    state.google_api_key);

    match client.post(&url).json(&request_body).send().await {
        Ok(resp) => {
            if let Ok(json) = resp.json::<serde_json::Value>().await {
                if let Some(text) = json["candidates"][0]["content"]["parts"][0]["text"].as_str() {
                    return Ok(text.to_string());
                } 
                else {
                    return Err("âŒ LLM å›å‚³æ ¼å¼éŒ¯èª¤æˆ–ç„¡å…§å®¹".into());
                }
            } else {
                return Err("âŒ ç„¡æ³•è§£æ LLM å›æ‡‰".into());
            }
        }
        Err(e) => return Err(format!("âŒ API å‘¼å«å¤±æ•—: {}", e).into())
    }
}

/* for JSON and then */

// --- 3. å•ç­”é‚è¼¯ ---
pub async fn process_query(
    state: &Arc<AppState>,
    history: &[Value],
    user_query: &str,
) -> Result<RagResponse, Box<dyn Error>> {
    
    let mut model = state.model.lock().await; 
    let db = &state.db;
    let synonyms = &state.synonyms;
    let summaries = &state.summaries;

    // --- è®€å–ç’°å¢ƒè®Šæ•¸ (è¨­å®šé è¨­å€¼ä»¥é˜²æ²’è¨­) ---
    let recall_limit = env::var("RAG_RECALL_LIMIT").ok().and_then(|v| v.parse().ok()).unwrap_or(20);
    let rerank_limit = env::var("RAG_RERANK_LIMIT").ok().and_then(|v| v.parse().ok()).unwrap_or(3);
    let rerank_api = env::var("RERANK_API_URL").unwrap_or("http://localhost:8000/rerank".to_string());
    // -------------------------------------
    // åœ¨ process_query ä¸€é–‹å§‹
    let mut normalized_query = user_query.to_string();

    // 1. å¼·åˆ¶å°‡æ•¸å­—èˆ‡ä¸­æ–‡ä¹‹é–“æ’å…¥ç©ºç™½
    // æŠŠ "30æ­²" è®Šæˆ "30 æ­²"ï¼ŒæŠŠ "100è¬" è®Šæˆ "100 è¬"
    let re_num_zh = Regex::new(r"(\d+)([\u4e00-\u9fa5])").unwrap();
    normalized_query = re_num_zh.replace_all(&normalized_query, "$1 $2").to_string();

    let re_zh_num = Regex::new(r"([\u4e00-\u9fa5])(\d+)").unwrap();
    normalized_query = re_zh_num.replace_all(&normalized_query, "$1 $2").to_string();

    println!("ğŸ”§ æ­£è¦åŒ–æŸ¥è©¢: '{}' -> '{}'", user_query, normalized_query);
    let mut search_target = normalized_query.clone();

    // 0. å­—å…¸æ“´å……
    // let mut final_query = user_query.to_string();
    for (slang, term) in synonyms {
        if user_query.contains(slang) {
            println!("ğŸ’¡ [å­—å…¸å‘½ä¸­] '{}' -> åŠ ä¸Š '{}'", slang, term);
            search_target.push_str(" ");
            search_target.push_str(term);
        }
    }

    let should_rewrite = history.len() > 1 && user_query.chars().count() < 50;
    if should_rewrite {
        println!("ğŸ¤” åµæ¸¬åˆ°çŸ­å•é¡Œä¸”æœ‰æ­·å²ï¼Œå˜—è©¦é€²è¡Œã€Œä¸»å‹•æ„åœ–æ”¹å¯«ã€...");
        if let Some(rewritten) = expand_query_with_ai(state, history, user_query).await {
            println!("âœ… AI æ”¹å¯«æˆåŠŸ: '{}'", rewritten);
            let mut final_rewritten = rewritten.clone();
            
            if user_query.len() > 6 && !final_rewritten.contains(user_query) {
                println!("âš ï¸ [é˜²å‘†è§¸ç™¼] AI æ”¹å¯«éºå¤±ä½¿ç”¨è€…é—œéµæ„åœ–ï¼Œå¼·åˆ¶è£œå›ï¼");
                final_rewritten.push_str(" ");
                final_rewritten.push_str(user_query);
            }

            search_target = final_rewritten;
            println!("âœ… æœ€çµ‚æœå°‹ç›®æ¨™: '{}'", search_target);
        }
    } 
    else {
        println!("â„¹ï¸ ç„¡éœ€ AI æ”¹å¯« (ç„¡æ­·å²æˆ–å•é¡Œå¤ å®Œæ•´)ï¼Œä½¿ç”¨åŸå§‹æŸ¥è©¢");
    }

    let forced_candidates: Vec<(String, String, f32)> = Vec::new();
    let mut forced_filenames = HashSet::new();
    let mut search_filter: Option<String> = None;

    let re = Regex::new(r#"[ã€ã€Œã€Šã€â€œ"â€˜'ï¼ˆ\(](.*?)[ã€ã€ã€‹ã€‘â€"â€™'ï¼‰\)]"#).unwrap();
    
    for cap in re.captures_iter(user_query) {
        let keyword = &cap[1]; // æå–åˆ°çš„é—œéµå­—ï¼Œä¾‹å¦‚ "æ´»åˆ©å„ªé€€"
        println!("ğŸ¯ åµæ¸¬åˆ°æ˜ç¢ºæ„åœ–é—œéµå­—: {}", keyword);

        // 2. æƒæ Summary æ‰¾å°æ‡‰æª”æ¡ˆ
        for (filename, summary) in &state.summaries {
            // è¦å‰‡ï¼šåªè¦æª”åæˆ–å•†å“å…¨ååŒ…å«é€™å€‹é—œéµå­— -> å‘½ä¸­
            if filename.contains(keyword) || summary.name.contains(keyword) {
                println!("âœ… é–å®šæª”æ¡ˆ: {}", filename);
                forced_filenames.insert(filename.clone());
            }
        }
    }
    // 3. å¦‚æœæœ‰é–å®šçš„æª”æ¡ˆï¼Œç›´æ¥å» DB æ’ˆå‡ºä¾† (ä¸é€éå‘é‡æœå°‹)
    if !forced_filenames.is_empty() {
        // çµ„è£ SQL Filter: source_file = 'A' OR source_file = 'B'
        let filter_cond = forced_filenames
            .iter()
            .map(|f| format!("source_file = '{}'", f))
            .collect::<Vec<_>>()
            .join(" OR ");

        search_filter = Some(filter_cond.clone());
    }

    println!("ğŸ” åŸ·è¡Œå‘é‡æœå°‹: {}", search_target);

    let mut vector_batches = search_in_lancedb(&mut *model, &db, &search_target, recall_limit, search_filter.clone()).await?;

    if vector_batches.is_empty() && search_target != user_query {
        println!("âš ï¸ [Fallback Triggered] ç²¾æº–æœå°‹ç„¡çµæœ ('{}')ï¼Œå˜—è©¦ä½¿ç”¨åŸå§‹å•é¡Œé‡æœ...", search_target);

        vector_batches = search_in_lancedb(&mut *model, &db, user_query, recall_limit, search_filter).await?;

        search_target = user_query.to_string();
    }


    let mut raw_candidates: Vec<(String, String)> = Vec::new();
    let mut seen_texts = HashSet::new();


    for (src, txt, _) in forced_candidates {
        if seen_texts.insert(txt.clone()) {
            raw_candidates.push((src, txt));
        }
    }


    for b in vector_batches {
        let src_col = b.column_by_name("source_file").unwrap().as_any().downcast_ref::<StringArray>().unwrap();
        let txt_col = b.column_by_name("text").unwrap().as_any().downcast_ref::<StringArray>().unwrap();

        for i in 0..b.num_rows() {
            let txt = txt_col.value(i).to_string();
            if seen_texts.insert(txt.clone()) {
                raw_candidates.push((
                    src_col.value(i).to_string(),
                    txt
                ));
            }
        }
    }


    if raw_candidates.is_empty() {
        return Ok(RagResponse {
            answer: "æŠ±æ­‰ï¼Œè³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚".to_string(),
            sources: vec![],
        });
    }
    // ğŸ”¥ [éå°ç¨±éæ¿¾ç­–ç•¥]
    // å®šç¾©éœ€è¦ã€Œåš´æ ¼éæ¿¾ã€çš„éšªç¨®ã€‚å£½éšªã€æ„å¤–éšªå› ç‚ºå¤ªå»£æ³›ï¼Œæ•…æ„ä¸åˆ—å…¥ï¼Œä¿æŒå¯¬é¬†ã€‚
    let strict_rules = vec![
        ("é†«ç™‚", vec!["é†«ç™‚", "æ‰‹è¡“", "ä½é™¢", "å¯¦æ”¯å¯¦ä»˜", "å¥åº·ä¿éšª"]),
        ("ç™Œç—‡", vec!["ç™Œç—‡", "é˜²ç™Œ", "æƒ¡æ€§è…«ç˜¤", "åŒ–ç™‚", "æ¨™é¶"]),
        ("é•·ç…§", vec!["é•·ç…§", "é•·æœŸç…§é¡§", "å¤±èƒ½", "æ‰¶åŠ©"]),
        ("æ‰“å·¥", vec!["æ‰“å·¥", "éŠå­¸", "åº¦å‡", "æµ·å¤–"]),
        ("æŠ•è³‡", vec!["æŠ•è³‡", "åŸºé‡‘", "è®Šé¡", "æ”¶ç›Š"]),
    ];

    let protected_rules = vec![
        ("å£½éšª", vec!["å£½éšª", "èº«æ•…", "äººå£½", "å„²è“„", "é‚„æœ¬"]),
        ("æ„å¤–", vec!["æ„å¤–", "å‚·å®³", "éª¨æŠ˜", "ç”¢éšª"]),
    ];

    let mut allowed_keywords: Vec<&str> = Vec::new();
    let mut strict_mode_triggered = false;


    for (category, keywords) in &strict_rules {
        if user_query.contains(category) {
            println!("ğŸ¯ åµæ¸¬åˆ°åš´æ ¼é¡åˆ¥æ„åœ–: [{}]", category);
            allowed_keywords.extend(keywords.iter().cloned());
            strict_mode_triggered = true;
        }
    }

    if strict_mode_triggered {
        for (category, keywords) in &protected_rules {
            if user_query.contains(category) {
                println!("ğŸ›¡ï¸ åµæ¸¬åˆ°æ··åˆæ„åœ–ï¼ŒåŠ å…¥å—ä¿è­·é¡åˆ¥: [{}]", category);
                allowed_keywords.extend(keywords.iter().cloned());
            }
        }
    }

    if !allowed_keywords.is_empty() {
        let before_count = raw_candidates.len();
        
        raw_candidates.retain(|(src, txt)| {
            // è¦å‰‡ï¼š(A OR B OR C...) åªè¦å‘½ä¸­å…¶ä¸­ä¸€çµ„é—œéµå­—å³å¯ä¿ç•™
            let src_match = allowed_keywords.iter().any(|&k| src.contains(k));
            let txt_match = allowed_keywords.iter().any(|&k| txt.chars().take(200).collect::<String>().contains(k));
            
            src_match || txt_match
        });

        println!("ğŸ§¹ æ··åˆéæ¿¾åŸ·è¡Œ: {} -> {} ç­† (é—œéµå­—è¯é›†: {:?})", 
            before_count, raw_candidates.len(), allowed_keywords);


        if raw_candidates.is_empty() {
             println!("âš ï¸ éæ¿¾å¾Œç„¡çµæœï¼Œå–æ¶ˆéæ¿¾æ¢ä»¶ã€‚");

        }
    }

    let top_results_all = rerank_documents(&search_target, raw_candidates, summaries, recall_limit, &rerank_api).await?;
    let top_results: Vec<(String, String, f32)> = top_results_all.into_iter().take(rerank_limit).collect();

    if top_results.is_empty() {
         return Ok(RagResponse {
            answer: "é›–ç„¶æœ‰ç›¸é—œæ–‡æª”ï¼Œä½†ç¶“éç›¸é—œæ€§æª¢æ¸¬å¾Œè¢«éæ¿¾æ‰äº†ã€‚".to_string(),
            sources: vec![],
        });
    }

    // 5. çµ„è£ Context (åŒ…å«å•†å“æ‘˜è¦)
    let mut hit_files = HashSet::new();
    let mut snippets_text = String::new();

    println!("\nğŸ” [RAG æª¢ç´¢çµæœ]");
   
    for (src, txt, score) in &top_results {
        hit_files.insert(src.clone());
        // æˆ‘å€‘å¯ä»¥åœ¨ context è£¡ç¨å¾®æ¨™è¨»ä¸€ä¸‹é€™æ˜¯ç²¾é¸å‡ºä¾†çš„
        snippets_text.push_str(&format!("ğŸ“„ [ç²¾é¸ç‰‡æ®µ] (é—œè¯åº¦:{:.1}) ä¾†æº: {}\nå…§å®¹: {}\n\n", score, src, txt));
    }

    // 6. æ³¨å…¥æ‘˜è¦ (Summary Injection)
    let mut final_context = String::new();
    final_context.push_str("=== ç›¸é—œå•†å“åŸºæœ¬ä»‹ç´¹ ===\n");
    for filename in &hit_files {
        if let Some(summary) = summaries.get(filename) {
            final_context.push_str(&format!("ğŸ“„ ä¾†æº: {}\n{}\n", filename, summary.intro));
        }
    }
    final_context.push_str("========================\n\n");
    final_context.push_str("=== è©³ç´°æª¢ç´¢ç‰‡æ®µ ===\n");
    final_context.push_str(&snippets_text);


    let llm_answer = ask_llm(state, &final_context, &search_target).await?;
    

    let mut sorted_sources: Vec<String> = hit_files.into_iter().collect();
    sorted_sources.sort();

    Ok(RagResponse {
        answer: llm_answer,
        sources: sorted_sources,
    })
}

pub async fn expand_query_with_ai(state: &Arc<AppState>, history: &[Value], query: &str) -> Option<String> {
    // å»ºç«‹æŒ‡ä»£æ¶ˆè§£å°ˆç”¨çš„ System Prompt
    let system_prompt = r#"
    ä½ æ˜¯ä¸€å€‹ RAG æœå°‹æ„åœ–å„ªåŒ–å°ˆå®¶ã€‚ä½ çš„ä»»å‹™æ˜¯çµåˆã€Œå°è©±æ­·å²ã€èˆ‡ã€Œæœ€æ–°å•é¡Œã€ï¼Œç”¢å‡ºæœ€ç²¾æº–çš„æœå°‹é—œéµå­—ã€‚

    ã€æ ¸å¿ƒè¦å‰‡ã€‘ï¼š
    1. **ç¹¼æ‰¿äººè¨­ (æœ€é‡è¦)**ï¼šæ°¸é ä¿ç•™æ­·å²ä¸­çš„ã€Œå¹´é½¡ã€ã€ã€Œæ€§åˆ¥ã€ã€ã€Œè·æ¥­ã€æˆ–ã€Œå®¶åº­ç‹€æ³ã€ç­‰è³‡è¨Šã€‚(ä¾‹å¦‚ï¼š30æ­²ç”·æ€§ã€ç‡Ÿé€ æ¥­)ã€‚
    2. **æ„åœ–åˆ‡æ› (Negative Check)**ï¼š
       - å¦‚æœæœ€æ–°å•é¡ŒåŒ…å«ã€Œä¸è¦...ã€ã€ã€Œæ”¹çœ‹...ã€ã€ã€Œä¸æ˜¯...ã€ç­‰å¦å®šè©ã€‚
       - **å¿…é ˆç§»é™¤** æ­·å²ä¸­è¢«å¦å®šçš„é—œéµå­— (ä¾‹å¦‚ï¼šä½¿ç”¨è€…èªªã€Œä¸è¦æŠ•è³‡å‹ã€ï¼Œä½ å°±è¦æŠŠã€ŒæŠ•è³‡ã€è®Šé¡ã€æ‹¿æ‰ï¼Œæ”¹åŠ å…¥ã€Œç´”å£½éšªã€å‚³çµ±å‹ã€)ã€‚
       - **è§£é™¤é–å®š**ï¼šä¸è¦å†åŠ å…¥ä¸Šä¸€è¼ªæ¨è–¦çš„å…·é«”ç”¢å“åç¨±ã€‚
    3. **ç”¢å“é–å®š**ï¼šåªæœ‰åœ¨ä½¿ç”¨è€…ã€Œè¿½å•ã€ç´°ç¯€ (å¦‚ï¼šé‚£è²»ç”¨å‘¢ï¼Ÿ) æ™‚ï¼Œæ‰é–å®šä¸Šä¸€è¼ªçš„ç”¢å“åç¨±ã€‚

    ã€åˆæˆç¯„ä¾‹ã€‘ï¼š
    History: 30æ­²ç”·æ€§, æ¨è–¦æŠ•è³‡å‹ -> AIæ¨è–¦å¯Œé‚¦æŠ•è³‡
    Current: "é‚£å¦‚æœä¸è¦æŠ•è³‡ï¼Œç´”ç²¹å£½éšªå‘¢ï¼Ÿ"
    Result: "30æ­²ç”·æ€§ çµ‚èº«å£½éšª å®šæœŸå£½éšª (æ’é™¤æŠ•è³‡å‹)"  <-- (é—œéµï¼šä¿ç•™å¹´é½¡ï¼Œä½†åˆ‡æ›éšªç¨®)

    History: 50æ­²å¥³æ€§ -> AIæ¨è–¦é˜²ç™Œéšª
    Current: "è²»ç”¨å¤šå°‘"
    Result: "50æ­²å¥³æ€§ é˜²ç™Œéšª è²»ç”¨è²»ç‡"

    è«‹ç›´æ¥è¼¸å‡ºå„ªåŒ–å¾Œçš„æœå°‹å­—ä¸²ã€‚
    "#;
    
    let history_text = history.iter()
        .rev() // å¾æ–°åˆ°èˆŠ
        .take(4)
        .rev() // è½‰å›ä¾†
        .map(|v| format!("{}: {}", v["role"].as_str().unwrap_or("unknown"), v["content"].as_str().unwrap_or("")))
        .collect::<Vec<String>>()
        .join("\n");

    let full_context = format!("å°è©±æ­·å²:\n{}\n\nä½¿ç”¨è€…æœ€æ–°å•é¡Œ: {}", history_text, query);

    println!("ğŸ¤– [AI æ”¹å¯«] æ­£åœ¨åˆ†ææ„åœ–...");

    let result = match state.llm_provider.as_str() {
        "local" => expand_local(state, system_prompt, &full_context).await,
        "google" => expand_google(state, system_prompt, &full_context).await,
        _ => expand_google(state, system_prompt, &full_context).await, // é è¨­ Google
    };

    match result {
        Ok(rewritten) => {
            let clean = rewritten.trim().replace("\n", " ");
            println!("âœ¨ åŸå§‹å•é¡Œ: {}", query);
            println!("âœ¨ æ”¹å¯«å¾Œå•é¡Œ: {}", clean);
            Some(clean)
        },
        Err(e) => {
            eprintln!("âŒ æ„åœ–æ”¹å¯«å¤±æ•—ï¼Œå°‡ä½¿ç”¨åŸå§‹å•é¡Œ: {}", e);
            None // å¤±æ•—å›å‚³ Noneï¼Œå¤–å±¤é‚è¼¯æœƒè‡ªå‹•é€€å›ä½¿ç”¨åŸå§‹ query
        }
    }
}


async fn expand_local(state: &Arc<AppState>, system_prompt: &str, user_content: &str) -> Result<String, Box<dyn Error>> {

    let client = reqwest::Client::builder()
        .no_proxy()
        .build()?;

    let base_url = state.local_llm_url.trim_end_matches('/');
    let api_url = if base_url.contains("/v1") {
        format!("{}/chat/completions", base_url)
    } else {
        format!("{}/v1/chat/completions", base_url)
    };

    let token = std::env::var("BEARER_TOKEN").unwrap_or_default();

    let body = json!({
        "model": state.local_llm_model,
        "messages": [
            { "role": "system", "content": system_prompt },
            { "role": "user", "content": user_content } 
        ],
        "temperature": 0.1, 
        "max_tokens": 1024   
    });

    let mut request_builder = client.post(&api_url)
        .header("Content-Type", "application/json");

    if !token.is_empty() && token != "none" {
        request_builder = request_builder.header("Authorization", format!("Bearer {}", token));
    }

    let resp = request_builder.json(&body).send().await?;
    let resp_status = resp.status();

    if resp.status().is_success() {
        let json: Value = resp.json().await?;
        if let Some(content) = json["choices"][0]["message"]["content"].as_str() {
            return Ok(content.to_string());
        }
    }
    
    Err(format!("Local LLM å›æ‡‰éŒ¯èª¤: {}", resp_status).into())
}


async fn expand_google(state: &Arc<AppState>, system_prompt: &str, user_content: &str) -> Result<String, Box<dyn Error>> {
    if state.google_api_key.is_empty() {
        return Err("ç¼ºå°‘ GOOGLE_API_KEY".into());
    }

   
    let client = reqwest::Client::new();

    
    let full_prompt = format!("{}\n\n{}", system_prompt, user_content);

    let url = format!(
        "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={}",
        state.google_api_key
    );

    let body = json!({
        "contents": [{ "parts": [{ "text": full_prompt }] }],
        "generationConfig": {
            "temperature": 0.1,
            "maxOutputTokens": 1024
        }
    });

    let resp = client.post(&url).json(&body).send().await?;

    let resp_status = resp.status();

    if resp.status().is_success() {
        let json: Value = resp.json().await?;
        if let Some(text) = json["candidates"][0]["content"]["parts"][0]["text"].as_str() {
            return Ok(text.to_string());
        }
    }

    Err(format!("Google API å›æ‡‰éŒ¯èª¤: {}", resp_status).into())
}


async fn rerank_documents(
    query: &str,
    candidates: Vec<(String, String)>, // (source_file, text)
    summaries: &HashMap<String, ProductSummary>,
    top_k: usize,
    api_url: &str
) -> Result<Vec<(String, String, f32)>, Box<dyn Error>> {

    let max_chunks_per_doc = env::var("MAX_CHUNKS_PER_DOC")
        .unwrap_or("3".to_string())
        .parse::<usize>()
        .unwrap_or(3);
    
    if candidates.is_empty() {
        return Ok(Vec::new());
    }


    let mut doc_texts_for_api: Vec<String> = Vec::new();

    for (src, txt) in &candidates {

        let content_for_judge = if let Some(sum) = summaries.get(src) {
            format!("{}\næ–‡ä»¶å…§å®¹: {}", sum.intro, txt)
        } else {
            txt.clone()
        };
        doc_texts_for_api.push(content_for_judge);
    }


    let client = reqwest::Client::builder()
        .no_proxy()
        .build()?;
    let request_body = RerankRequest {
        query: query.to_string(),
        documents: doc_texts_for_api,
    };

    println!("âš–ï¸ æ­£åœ¨é€²è¡Œ Re-ranking ({} ç­†å€™é¸, å– Top {} åˆ° {})...", candidates.len(), top_k, api_url);

    let rerank_response_result = client.post(api_url)
        .json(&request_body)
        .send()
        .await;

    // 2. åˆ¤æ–·é€£ç·šçµæœ
    let rerank_res: RerankResponse = match rerank_response_result {
        Ok(resp) if resp.status().is_success() => {

            match resp.json::<RerankResponse>().await {
                Ok(res) => res, 
                Err(e) => {
                    println!("âš ï¸ [é Demo æ™‚é–“] Rerank JSON è§£æå¤±æ•—: {}", e);
                    
                    RerankResponse { indices: vec![], scores: vec![] } 
                }
            }
        },
        Ok(resp) => {
            
            println!("âš ï¸ [é Demo æ™‚é–“] Rerank Server å›å‚³éŒ¯èª¤ä»£ç¢¼: {}", resp.status());
            RerankResponse { indices: vec![], scores: vec![] }
        },
        Err(e) => {
            
            println!("âš ï¸ [é Demo æ™‚é–“] ç„¡æ³•é€£ç·šè‡³ Rerank Server: {}", e);
            RerankResponse { indices: vec![], scores: vec![] }
        }
    };


    let mut ranked_results = Vec::new();
    let mut file_counts: HashMap<String, usize> = HashMap::new();
    

    if !rerank_res.indices.is_empty() {

        println!("âœ… Rerank æˆåŠŸï¼Œä½¿ç”¨ AI é‡æ’åºçµæœ...");
        for (i, &original_idx) in rerank_res.indices.iter().enumerate() {
            if ranked_results.len() >= top_k { break; }
            
            let score = rerank_res.scores[i];
            

            if score < -5.0 { continue; }

            if let Some((src, txt)) = candidates.get(original_idx) {
                let count = file_counts.entry(src.clone()).or_insert(0);
                if *count < max_chunks_per_doc {
                    println!("   â­ [Top {}] åˆ†æ•¸: {:.2} | ä¾†æº: {}", i+1, score, src);
                    ranked_results.push((src.clone(), txt.clone(), score));
                    *count += 1;
                }
            }
        }
    } 
    else {
        
        println!("ğŸ›Œ Rerank ä¼‘æ¯ä¸­ï¼Œç›´æ¥å›å‚³ LanceDB åŸå§‹æ’åº...");
        
        
        for (i, (src, txt)) in candidates.iter().enumerate() {
            if ranked_results.len() >= top_k { break; }

            
            let count = file_counts.entry(src.clone()).or_insert(0);
            
            if *count < max_chunks_per_doc {
                
                let fake_score = 0.0; 
                println!("   ğŸ“¦ [åŸå§‹çµæœ {}] ä¾†æº: {}", i+1, src);
                ranked_results.push((src.clone(), txt.clone(), fake_score));
                *count += 1;
            }
        }
    }

    Ok(ranked_results)
}


pub async fn init_system() -> Result<Arc<AppState>, Box<dyn Error>> {
    dotenv().ok();
    
    let db_path = std::env::var("LANCEDB_PATH").unwrap_or(DB_URI.to_string());
    println!("ğŸ“‚ é€£æ¥ LanceDB è·¯å¾‘: {}", db_path);
    let db = connect(&db_path).execute().await?;
    
    println!("ğŸ§  è¼‰å…¥ Embedding æ¨¡å‹...");
    let cache_dir = env::var("FASTEMBED_CACHE_PATH")
        .unwrap_or_else(|_| ".fastembed_cache".to_string());
    
    println!("ğŸ“‚ ä½¿ç”¨æ¨¡å‹å¿«å–è·¯å¾‘: {}", cache_dir);

    // 2. è¨­å®šé¸é …
    let mut model = TextEmbedding::try_new(
        InitOptions::new(EmbeddingModel::BGESmallZHV15)
            // ğŸ”¥ [é—œéµ] é¡¯å¼æŒ‡å®š Cache è·¯å¾‘
            .with_cache_dir(PathBuf::from(cache_dir)) 
            .with_show_download_progress(true)
    )?;
    
    let (summaries, synonyms) = sync_database_and_load_cache(&db, &mut model).await?;
    let llm_provider = env::var("LLM_PROVIDER").unwrap_or("google".to_string());
    let google_api_key = env::var("GOOGLE_API_KEY").unwrap_or_default();
    let local_llm_url = env::var("VLLM_ENDPOINT").unwrap_or("http://localhost:8000/v1/chat/completions".to_string());
    let local_llm_model = env::var("MODEL_NAME").unwrap_or("local-model".to_string());

    let redis_pool = match env::var("REDIS_URL") {
        Ok(url) => {

            match Config::from_url(url).create_pool(Some(Runtime::Tokio1)) {
                Ok(pool) => {
                    match pool.get().await {
                        Ok(_) => {
                            println!("âœ… Redis é€£ç·šæ± å»ºç«‹æˆåŠŸ (Deadpool) - é€£ç·šæ¸¬è©¦é€šé");
                            Some(pool)
                        },
                        Err(e) => {
                            eprintln!("âš ï¸ Redis è¨­å®šæ ¼å¼æ­£ç¢ºï¼Œä½†ç„¡æ³•é€£ç·šè‡³ Server: {}", e);
                            eprintln!("   (å°‡é™ç´šä½¿ç”¨ç´”è¨˜æ†¶é«”æ¨¡å¼)");
                            None 
                        }
                    }
 
                },
                Err(e) => {
                    eprintln!("âš ï¸ Redis è¨­å®šå¤±æ•—ï¼Œå°‡ä½¿ç”¨ç´”å‰ç«¯è¨˜æ†¶æ¨¡å¼: {}", e);
                    None
                }
            }
        },
        Err(_) => {
            println!("â„¹ï¸ æœªè¨­å®š REDIS_URLï¼Œå°‡ä½¿ç”¨ç´”å‰ç«¯è¨˜æ†¶æ¨¡å¼");
            None
        }
    };

    Ok(Arc::new(AppState {
        db,
        model: Mutex::new(model),
        synonyms,
        summaries,
        llm_provider,
        google_api_key,
        local_llm_url,
        local_llm_model,
        redis_pool,
    }))
}


async fn search_in_lancedb(
    model: &mut TextEmbedding,
    db: &lancedb::Connection,
    query_text: &str,
    limit: usize,
    filter: Option<String> 
) -> Result<Vec<RecordBatch>, Box<dyn Error>> {
    

    let query_vec = model.embed(vec![query_text.to_string()], None)?[0].clone();

    let table = db.open_table(TABLE_NAME).execute().await?;

    let mut query_builder = table
        .query()
        .nearest_to(query_vec)?
        .limit(limit);

    if let Some(f) = filter {
        println!("ğŸ” [Vector Search] å¥—ç”¨éæ¿¾æ¢ä»¶: {}", f);
        query_builder = query_builder.only_if(f);
    }

    let results = query_builder.execute().await?;


    let batches: Vec<RecordBatch> = results.try_collect().await?;
    Ok(batches)
}

pub async fn sync_database_and_load_cache(
    db: &lancedb::Connection,
    model: &mut TextEmbedding
) -> Result<(HashMap<String, ProductSummary>, HashMap<String, String>), Box<dyn Error>> {
    
    println!("ğŸ”„ é–‹å§‹åŸ·è¡Œè³‡æ–™åŒæ­¥èˆ‡å¿«å–è¼‰å…¥...");


    let mut summaries = HashMap::new();
    let mut synonyms = HashMap::new();


    let table_names = db.table_names().execute().await?;
    let table_exists = table_names.contains(&TABLE_NAME.to_string());

    let table = if !table_exists {
        println!("âœ¨ è³‡æ–™è¡¨ä¸å­˜åœ¨ï¼Œå»ºç«‹æ–°è¡¨...");

        let schema = Arc::new(Schema::new(vec![
            Field::new("source_file", DataType::Utf8, false),
            Field::new("file_hash", DataType::Utf8, false), 
            Field::new("text", DataType::Utf8, false),
            Field::new("vector", DataType::FixedSizeList(
                Arc::new(Field::new("item", DataType::Float32, true)),
                512 
            ), false),
        ]));
        db.create_table(TABLE_NAME, RecordBatchIterator::new(vec![], schema)).execute().await?
    } else {
        db.open_table(TABLE_NAME).execute().await?
    };

    
    let mut existing_hashes: HashMap<String, String> = HashMap::new();
    
    if table_exists {
        
        match table.query()
            .select(Select::Columns(vec!["source_file".to_string(), "file_hash".to_string()]))
            .limit(10000)
            .execute()
            .await {
            Ok(mut stream) => {
                while let Ok(Some(batch)) = stream.try_next().await {
                    let src_col = batch.column_by_name("source_file").unwrap().as_any().downcast_ref::<StringArray>().unwrap();
                    let hash_col = batch.column_by_name("file_hash").unwrap().as_any().downcast_ref::<StringArray>().unwrap();
                    
                    for i in 0..batch.num_rows() {
                        let src = src_col.value(i).to_string();
                        let h = hash_col.value(i).to_string();
                        // å¯èƒ½æœ‰å¤šå€‹ chunk å°æ‡‰åŒä¸€å€‹æª”æ¡ˆï¼Œæˆ‘å€‘åªéœ€è¦å­˜ä¸€æ¬¡
                        existing_hashes.insert(src, h);
                    }
                }
            },
            Err(_) => println!("âš ï¸ ç„¡æ³•è®€å–èˆŠ Hashï¼Œå°‡è¦–ç‚ºå…¨éƒ¨é‡æ–°å¯«å…¥ã€‚"),
        }
    }
    
    println!("ğŸ“Š ç›®å‰ DB å·²ç´¢å¼• {} ä»½æ–‡ä»¶", existing_hashes.len());

    let walker = WalkDir::new(PROCESSED_JSON_DIR).into_iter();
    let mut new_chunks_buffer: Vec<(String, String, String)> = Vec::new(); 
    let mut updated_count = 0;
    let mut skipped_count = 0;
    let mut parse_error_count = 0;

    for entry in walker.filter_map(|e| e.ok()) {
        let path = entry.path();
        if path.extension().map_or(false, |e| e == "json") {
            //if let Ok(content) = fs::read_to_string(path) {
            let content = match fs::read_to_string(path) {
                Ok(c) => c,
                Err(e) => {
                    eprintln!("âŒ ç„¡æ³•è®€å–æª”æ¡ˆ {:?}: {}", path, e);
                    continue;
                }
            };

            
            match serde_json::from_str::<models::PolicyData>(&content) {
                Ok(data) => {
                    
                    let intro = format!(
                        "ã€å•†å“ç¸½è¦½ã€‘\nåç¨±: {}\né¡å‹: {}\nç‰¹è‰²: {:?}\né©åˆå°è±¡: {}\n",
                        data.basic_info.product_name,
                        data.basic_info.product_type,
                        data.investment.features,
                        data.rag_data.target_audience
                    );
                    summaries.insert(data.source_filename.clone(), ProductSummary {
                        name: data.basic_info.product_name.clone(), 
                        intro: intro.clone(),
                    });


                    if let Some(mapping) = &data.rag_data.synonym_mapping {
                        let count_before = synonyms.len();
                        for entry in mapping {
                            let slangs: Vec<&str> = entry.slang.split(&['ã€', ','][..]).collect();
                            for s in slangs {
                                let clean_s = s.trim().to_string();
                                if !clean_s.is_empty() {
                                    synonyms.insert(clean_s, entry.formal.clone());
                                }
                            }
                        }
                        
                        println!("   ğŸ“š {} è¼‰å…¥ {} å€‹åŒç¾©è©", data.source_filename, synonyms.len() - count_before);
                    } 
                    else {
                        
                        println!("   âš ï¸ {} æ²’æœ‰åŒç¾©è©è¨­å®š (synonym_mapping is null)", data.source_filename);
                    }

                    
                    let current_hash = calculate_hash(&content);
                    let filename = data.source_filename.clone();
                    
                
                    let needs_update = match existing_hashes.get(&filename) {
                        Some(old_hash) => *old_hash != current_hash,
                        None => true, 
                    };

                    if needs_update {
                        if existing_hashes.contains_key(&filename) {
                            println!("ğŸ“ [è®Šæ›´] {} å…§å®¹å·²ä¿®ï¼Œæ›´æ–° DB...", filename);
                            table.delete(&format!("source_file = '{}'", filename)).await?;
                        } 
                        else {
                            println!("â• [æ–°å¢] {}", filename);
                        }
                        let mut final_chunks = Vec::new();

                        if !data.rag_data.chunks.is_empty() {
                            
                            final_chunks = data.rag_data.chunks;
                        } 
                        else {
                            
                            println!("   âš™ï¸ è‡ªå‹•çµ„è£å…§å®¹...");
                            
                            
                            let chunk_intro = format!(
                                "æ–‡ä»¶æ¨™é¡Œ: {}\n{}\nã€æŠ•ä¿è¦å‰‡ã€‘\nå¹´é½¡: {}\nä¿è²»é™åˆ¶: {}\nè²»ç”¨: {}\nã€ä¿éšœå…§å®¹ã€‘\nèº«æ•…: {}\næ»¿æœŸ: {}\nå…¶ä»–: {:?}\nã€æŠ•è³‡ç‰¹è‰²ã€‘\n{:?}\né¢¨éšª: {:?}",
                                data.source_filename,
                                intro, 
                                data.conditions.age_range,
                                data.conditions.premium_limit,
                                data.conditions.fees_and_discounts,
                                data.coverage.death_benefit,
                                data.coverage.maturity_benefit,
                                data.coverage.other_benefits,
                                data.investment.features,
                                data.investment.risks
                            );
                            final_chunks.push(chunk_intro);

                            
                            let faqs = &data.rag_data.faq;
                            if !faqs.is_empty() {
                                let mut faq_buffer = String::from("ã€å¸¸è¦‹å•ç­” FAQã€‘\n");
                                for (i, qa) in faqs.iter().enumerate() {
                                    faq_buffer.push_str(&format!("Q: {}\nA: {}\n\n", qa.q, qa.a));
                                    
                                    
                                    if (i + 1) % 3 == 0 || i == faqs.len() - 1 {
                                        final_chunks.push(faq_buffer.clone());
                                        faq_buffer = String::from("ã€å¸¸è¦‹å•ç­” FAQ (çºŒ)ã€‘\n");
                                    }
                                }
                            }
                        }

                        for chunk_text in final_chunks {
                            
                            new_chunks_buffer.push((filename.clone(), current_hash.clone(), chunk_text));
                        }
                        updated_count += 1;
                    } 
                    else {
                        skipped_count += 1;
                    }
                },
                Err(e) => {
                    
                    eprintln!("âŒ JSON è§£æå¤±æ•— {:?}: {}", path.file_name().unwrap(), e);
                    parse_error_count += 1;
                }
            }
        }
    }

    println!("ğŸ” æƒæçµ±è¨ˆ:");
    println!("   - âœ… æˆåŠŸè¼‰å…¥æ‘˜è¦: {} ç­†", summaries.len());
    println!("   - âœ… æˆåŠŸè¼‰å…¥åŒç¾©è©: {} ç­†", synonyms.len());
    println!("   - â­ï¸ è³‡æ–™åº«ç•¥é (ç„¡è®Šæ›´): {} ä»½", skipped_count);
    println!("   - â™»ï¸ è³‡æ–™åº«æ›´æ–° (æœ‰è®Šæ›´): {} ä»½", updated_count);
    if parse_error_count > 0 {
        println!("   - âŒ è§£æå¤±æ•— (è«‹æª¢æŸ¥ models.rs): {} ä»½", parse_error_count);
    }
    
    if !new_chunks_buffer.is_empty() {
        println!("ğŸš€ æ­£åœ¨å° {} å€‹æ–°æ®µè½é€²è¡Œ Embedding...", new_chunks_buffer.len());
        
        let batch_size = 50;
        for chunk in new_chunks_buffer.chunks(batch_size) {
            let texts: Vec<String> = chunk.iter().map(|(_, _, t)| t.clone()).collect();
            let sources: Vec<String> = chunk.iter().map(|(s, _, _)| s.clone()).collect();
            let hashes: Vec<String> = chunk.iter().map(|(_, h, _)| h.clone()).collect();
            
           
            let embeddings = model.embed(texts.clone(), None)?;
            
            
            let flat_vectors: Vec<f32> = embeddings.iter().flat_map(|v| v.clone()).collect();
            let dim = 512; // BGE-M3
            let schema = table.schema().await?;
            let batch = RecordBatch::try_new(
                schema.clone(),
                vec![
                    Arc::new(StringArray::from(sources)),
                    Arc::new(StringArray::from(hashes)),
                    Arc::new(StringArray::from(texts)),
                    Arc::new(FixedSizeListArray::new(
                        Arc::new(Field::new("item", DataType::Float32, true)),
                        dim,
                        Arc::new(Float32Array::from(flat_vectors)),
                        None,
                    )),
                ],
            )?;
            let iterator = RecordBatchIterator::new(
            vec![Ok(batch)], 
                schema.clone()
            );
            table.add(iterator).execute().await?;
        }
        println!("âœ… è³‡æ–™åº«åŒæ­¥å®Œæˆï¼");
    } 
    else {
        println!("âœ… è³‡æ–™åº«å·²æ˜¯æœ€æ–°ç‹€æ…‹ï¼Œç„¡éœ€å¯«å…¥ã€‚");
    }

    Ok((summaries, synonyms))
}